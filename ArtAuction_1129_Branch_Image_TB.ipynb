{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ArtAuction_1129_Branch_Image_TB.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gohenry/DataScienceCoursera/blob/master/ArtAuction_1129_Branch_Image_TB.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lt4UBerZ8ya7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#pip install --user --upgrade tensorflow"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e8ZLzTDiKU3i",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 816
        },
        "outputId": "93e96a68-e712-4e3e-dc8a-d01e774d77f5"
      },
      "source": [
        "import tensorflow as tf\n",
        "help(tf)\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Help on package tensorflow:\n",
            "\n",
            "NAME\n",
            "    tensorflow - TensorFlow root package\n",
            "\n",
            "PACKAGE CONTENTS\n",
            "\n",
            "\n",
            "DATA\n",
            "    __compiler_version__ = '7.3.1 20180303'\n",
            "    __cxx11_abi_flag__ = 0\n",
            "    __git_version__ = 'v2.0.0-rc2-26-g64c3d38'\n",
            "    __monolithic_build__ = 0\n",
            "    bfloat16 = tf.bfloat16\n",
            "    bool = tf.bool\n",
            "    complex128 = tf.complex128\n",
            "    complex64 = tf.complex64\n",
            "    double = tf.float64\n",
            "    float16 = tf.float16\n",
            "    float32 = tf.float32\n",
            "    float64 = tf.float64\n",
            "    half = tf.float16\n",
            "    int16 = tf.int16\n",
            "    int32 = tf.int32\n",
            "    int64 = tf.int64\n",
            "    int8 = tf.int8\n",
            "    newaxis = None\n",
            "    qint16 = tf.qint16\n",
            "    qint32 = tf.qint32\n",
            "    qint8 = tf.qint8\n",
            "    quint16 = tf.quint16\n",
            "    quint8 = tf.quint8\n",
            "    resource = tf.resource\n",
            "    string = tf.string\n",
            "    uint16 = tf.uint16\n",
            "    uint32 = tf.uint32\n",
            "    uint64 = tf.uint64\n",
            "    uint8 = tf.uint8\n",
            "    variant = tf.variant\n",
            "\n",
            "VERSION\n",
            "    2.0.0\n",
            "\n",
            "FILE\n",
            "    /root/.local/lib/python3.6/site-packages/tensorflow/__init__.py\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vQehzGIK_d1T",
        "colab_type": "code",
        "outputId": "c13dce2a-f191-4b26-da09-cab84470479a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount ('/content/drive', force_remount = True)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MzosBaOfNRIO",
        "colab_type": "code",
        "outputId": "a7d08797-cfd8-4e32-8abb-1cc604e142a0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "cd /content/drive/My Drive"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v3bFX7bd_jIk",
        "colab_type": "code",
        "outputId": "7355eb8d-fcf7-4d79-eb17-97a8402d316a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#import the necessary packages\n",
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "import functools\n",
        "import pydot\n",
        "import keras\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "from keras import layers\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import Input, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D\n",
        "from keras.layers import AveragePooling2D, MaxPooling2D, Dropout, GlobalMaxPooling2D, GlobalAveragePooling2D\n",
        "from keras.models import Model\n",
        "from keras.models import Sequential\n",
        "from keras.preprocessing import image\n",
        "from keras.utils import np_utils\n",
        "from keras.utils import layer_utils\n",
        "from keras.utils import plot_model\n",
        "from keras.utils.vis_utils import model_to_dot\n",
        "from keras.utils.data_utils import get_file\n",
        "from keras.applications.imagenet_utils import preprocess_input\n",
        "import keras.backend as K\n",
        "K.set_image_data_format('channels_last')\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "from matplotlib.pyplot import imshow\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg \n",
        "\n",
        "from IPython.display import SVG\n",
        "\n",
        "\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xxpxKtnT_wzt",
        "colab_type": "code",
        "outputId": "a5e9be60-92b3-4108-a97a-5eacbc4300fa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 949
        }
      },
      "source": [
        "#load numerical data using Pandas\n",
        "!pip install -q xlrd\n",
        "!pip install pillow\n",
        "\n",
        "cols = ['author','creation_year','height(inch)','width(inch)','estimate_low($)','estimate_high','auction_year','artist_birth','hammer price', 'artist_rank','artist_points','num_bill','wealth_bill','canvas','paper','Acrylic','oil','Mixed media','image']\n",
        "df = pd.read_excel('result_2009.xlsx', usecols=cols)\n",
        "df = pd.get_dummies(df, prefix=['auth'], columns = ['author'])\n",
        "df\n",
        "\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pillow in /usr/local/lib/python3.6/dist-packages (4.3.0)\n",
            "Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from pillow) (0.46)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>creation_year</th>\n",
              "      <th>height(inch)</th>\n",
              "      <th>width(inch)</th>\n",
              "      <th>estimate_low($)</th>\n",
              "      <th>estimate_high</th>\n",
              "      <th>hammer price</th>\n",
              "      <th>auction_year</th>\n",
              "      <th>image</th>\n",
              "      <th>artist_birth</th>\n",
              "      <th>artist_rank</th>\n",
              "      <th>artist_points</th>\n",
              "      <th>num_bill</th>\n",
              "      <th>wealth_bill</th>\n",
              "      <th>canvas</th>\n",
              "      <th>paper</th>\n",
              "      <th>Acrylic</th>\n",
              "      <th>Mixed media</th>\n",
              "      <th>oil</th>\n",
              "      <th>auth_Ai Weiwei</th>\n",
              "      <th>auth_Alberto Giacometti</th>\n",
              "      <th>auth_Alex Katz</th>\n",
              "      <th>auth_Alexander Calder</th>\n",
              "      <th>auth_Alighiero Boëtti</th>\n",
              "      <th>auth_Andy Warhol</th>\n",
              "      <th>auth_Anselm Kiefer</th>\n",
              "      <th>auth_Antoni Tàpies</th>\n",
              "      <th>auth_Arnulf Rainer</th>\n",
              "      <th>auth_Carl Andre</th>\n",
              "      <th>auth_Christian Boltanski</th>\n",
              "      <th>auth_Christian Marclay</th>\n",
              "      <th>auth_Cindy Sherman</th>\n",
              "      <th>auth_Claes Oldenburg</th>\n",
              "      <th>auth_Cy Twombly</th>\n",
              "      <th>auth_Damien Hirst</th>\n",
              "      <th>auth_Dan Graham</th>\n",
              "      <th>auth_Daniel Buren</th>\n",
              "      <th>auth_David Hockney</th>\n",
              "      <th>auth_Dieter Roth</th>\n",
              "      <th>auth_Douglas Gordon</th>\n",
              "      <th>auth_Ed Ruscha</th>\n",
              "      <th>...</th>\n",
              "      <th>auth_Joseph Beuys</th>\n",
              "      <th>auth_Kader Attia</th>\n",
              "      <th>auth_Kiki Smith</th>\n",
              "      <th>auth_Lawrence Weiner</th>\n",
              "      <th>auth_Louise Bourgeois</th>\n",
              "      <th>auth_Lucio Fontana</th>\n",
              "      <th>auth_Man Ray</th>\n",
              "      <th>auth_Marcel Broodthaers</th>\n",
              "      <th>auth_Marcel Duchamp</th>\n",
              "      <th>auth_Maria Lassnig</th>\n",
              "      <th>auth_Marina Abramovic</th>\n",
              "      <th>auth_Marlene Dumas</th>\n",
              "      <th>auth_Martin Kippenberger</th>\n",
              "      <th>auth_Max Ernst</th>\n",
              "      <th>auth_Mike Kelley</th>\n",
              "      <th>auth_Mona Hatoum</th>\n",
              "      <th>auth_Nam June Paik</th>\n",
              "      <th>auth_Olafur Eliasson</th>\n",
              "      <th>auth_Pablo Picasso</th>\n",
              "      <th>auth_Paul Klee</th>\n",
              "      <th>auth_Paul McCarthy</th>\n",
              "      <th>auth_Pierre Huyghe</th>\n",
              "      <th>auth_Richard Long</th>\n",
              "      <th>auth_Richard Prince</th>\n",
              "      <th>auth_Richard Serra</th>\n",
              "      <th>auth_Rirkrit Tiravanija</th>\n",
              "      <th>auth_Robert Mapplethorpe</th>\n",
              "      <th>auth_Robert Rauschenberg</th>\n",
              "      <th>auth_Rosemarie Trockel</th>\n",
              "      <th>auth_Roy Lichtenstein</th>\n",
              "      <th>auth_Sigmar Polke</th>\n",
              "      <th>auth_Sol LeWitt</th>\n",
              "      <th>auth_Tacita Dean</th>\n",
              "      <th>auth_Thomas Ruff</th>\n",
              "      <th>auth_Thomas Schütte</th>\n",
              "      <th>auth_Tony Cragg</th>\n",
              "      <th>auth_Valie Export</th>\n",
              "      <th>auth_William Kentridge</th>\n",
              "      <th>auth_Yayoi Kusama</th>\n",
              "      <th>auth_Yoko Ono</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1964.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>150000.0</td>\n",
              "      <td>200000.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2019.0</td>\n",
              "      <td>images/Andy Warhol-Flowers-1-0.jpg</td>\n",
              "      <td>1928.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>51496.69</td>\n",
              "      <td>2153.0</td>\n",
              "      <td>8.7</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1964.0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>1500000.0</td>\n",
              "      <td>2000000.0</td>\n",
              "      <td>1150000.0</td>\n",
              "      <td>2019.0</td>\n",
              "      <td>images/Andy Warhol-Flowers-1-1.jpg</td>\n",
              "      <td>1928.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>51496.69</td>\n",
              "      <td>2153.0</td>\n",
              "      <td>8.7</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1985.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>60000.0</td>\n",
              "      <td>80000.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2019.0</td>\n",
              "      <td>images/Andy Warhol-Self-Defense (Positive)-1-2...</td>\n",
              "      <td>1928.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>51496.69</td>\n",
              "      <td>2153.0</td>\n",
              "      <td>8.7</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1985.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>60000.0</td>\n",
              "      <td>80000.0</td>\n",
              "      <td>50000.0</td>\n",
              "      <td>2019.0</td>\n",
              "      <td>images/Andy Warhol-Self-Defense (Negative)-1-3...</td>\n",
              "      <td>1928.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>51496.69</td>\n",
              "      <td>2153.0</td>\n",
              "      <td>8.7</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1983.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>50000.0</td>\n",
              "      <td>70000.0</td>\n",
              "      <td>70000.0</td>\n",
              "      <td>2019.0</td>\n",
              "      <td>images/Andy Warhol-Untitled (Four)-1-4.jpg</td>\n",
              "      <td>1928.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>51496.69</td>\n",
              "      <td>2153.0</td>\n",
              "      <td>8.7</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14699</th>\n",
              "      <td>1999.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>149320.0</td>\n",
              "      <td>223980.0</td>\n",
              "      <td>313572.0</td>\n",
              "      <td>2010.0</td>\n",
              "      <td>images/Marlene Dumas-Dancer-3-13.jpg</td>\n",
              "      <td>1953.0</td>\n",
              "      <td>114.0</td>\n",
              "      <td>14262.10</td>\n",
              "      <td>1011.0</td>\n",
              "      <td>3.6</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14700</th>\n",
              "      <td>1994.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>218820.0</td>\n",
              "      <td>281340.0</td>\n",
              "      <td>484530.0</td>\n",
              "      <td>2010.0</td>\n",
              "      <td>images/Marlene Dumas-\"The Peeping Tom \"-3-14.jpg</td>\n",
              "      <td>1953.0</td>\n",
              "      <td>114.0</td>\n",
              "      <td>14262.10</td>\n",
              "      <td>1011.0</td>\n",
              "      <td>3.6</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14701</th>\n",
              "      <td>1995.0</td>\n",
              "      <td>79.0</td>\n",
              "      <td>39.0</td>\n",
              "      <td>250000.0</td>\n",
              "      <td>350000.0</td>\n",
              "      <td>440000.0</td>\n",
              "      <td>2009.0</td>\n",
              "      <td>images/Marlene Dumas-Evil Eye-3-15.jpg</td>\n",
              "      <td>1953.0</td>\n",
              "      <td>98.0</td>\n",
              "      <td>14765.08</td>\n",
              "      <td>793.0</td>\n",
              "      <td>2.4</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14702</th>\n",
              "      <td>1996.0</td>\n",
              "      <td>49.0</td>\n",
              "      <td>27.0</td>\n",
              "      <td>70000.0</td>\n",
              "      <td>100000.0</td>\n",
              "      <td>60000.0</td>\n",
              "      <td>2009.0</td>\n",
              "      <td>images/Marlene Dumas-Transparent Slip-3-16.jpg</td>\n",
              "      <td>1953.0</td>\n",
              "      <td>98.0</td>\n",
              "      <td>14765.08</td>\n",
              "      <td>793.0</td>\n",
              "      <td>2.4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14703</th>\n",
              "      <td>1986.0</td>\n",
              "      <td>39.0</td>\n",
              "      <td>23.0</td>\n",
              "      <td>1133.0</td>\n",
              "      <td>1700.0</td>\n",
              "      <td>1077.0</td>\n",
              "      <td>2018.0</td>\n",
              "      <td>images/Pierre Huyghe-Sans titre double-face-1-...</td>\n",
              "      <td>1962.0</td>\n",
              "      <td>98.0</td>\n",
              "      <td>12992.24</td>\n",
              "      <td>2208.0</td>\n",
              "      <td>9.1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>14704 rows × 106 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       creation_year  height(inch)  ...  auth_Yayoi Kusama  auth_Yoko Ono\n",
              "0             1964.0           5.0  ...                  0              0\n",
              "1             1964.0          22.0  ...                  0              0\n",
              "2             1985.0          20.0  ...                  0              0\n",
              "3             1985.0          20.0  ...                  0              0\n",
              "4             1983.0          20.0  ...                  0              0\n",
              "...              ...           ...  ...                ...            ...\n",
              "14699         1999.0           2.0  ...                  0              0\n",
              "14700         1994.0           2.0  ...                  0              0\n",
              "14701         1995.0          79.0  ...                  0              0\n",
              "14702         1996.0          49.0  ...                  0              0\n",
              "14703         1986.0          39.0  ...                  0              0\n",
              "\n",
              "[14704 rows x 106 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-cRDwRTDeeQ1",
        "colab_type": "code",
        "outputId": "5d5514d1-02e1-46dd-c218-8264a0e8608c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 915
        }
      },
      "source": [
        "#drop rows containing missing data\n",
        "ccols = ['creation_year','height(inch)','width(inch)','estimate_low($)','estimate_high','auction_year','artist_birth','hammer price', 'artist_rank','artist_points','num_bill','wealth_bill','canvas','paper','Acrylic','oil','Mixed media']\n",
        "df[ccols] = df[ccols].apply(pd.to_numeric, errors='coerce')\n",
        "df = df.dropna()\n",
        "df"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>creation_year</th>\n",
              "      <th>height(inch)</th>\n",
              "      <th>width(inch)</th>\n",
              "      <th>estimate_low($)</th>\n",
              "      <th>estimate_high</th>\n",
              "      <th>hammer price</th>\n",
              "      <th>auction_year</th>\n",
              "      <th>image</th>\n",
              "      <th>artist_birth</th>\n",
              "      <th>artist_rank</th>\n",
              "      <th>artist_points</th>\n",
              "      <th>num_bill</th>\n",
              "      <th>wealth_bill</th>\n",
              "      <th>canvas</th>\n",
              "      <th>paper</th>\n",
              "      <th>Acrylic</th>\n",
              "      <th>Mixed media</th>\n",
              "      <th>oil</th>\n",
              "      <th>auth_Ai Weiwei</th>\n",
              "      <th>auth_Alberto Giacometti</th>\n",
              "      <th>auth_Alex Katz</th>\n",
              "      <th>auth_Alexander Calder</th>\n",
              "      <th>auth_Alighiero Boëtti</th>\n",
              "      <th>auth_Andy Warhol</th>\n",
              "      <th>auth_Anselm Kiefer</th>\n",
              "      <th>auth_Antoni Tàpies</th>\n",
              "      <th>auth_Arnulf Rainer</th>\n",
              "      <th>auth_Carl Andre</th>\n",
              "      <th>auth_Christian Boltanski</th>\n",
              "      <th>auth_Christian Marclay</th>\n",
              "      <th>auth_Cindy Sherman</th>\n",
              "      <th>auth_Claes Oldenburg</th>\n",
              "      <th>auth_Cy Twombly</th>\n",
              "      <th>auth_Damien Hirst</th>\n",
              "      <th>auth_Dan Graham</th>\n",
              "      <th>auth_Daniel Buren</th>\n",
              "      <th>auth_David Hockney</th>\n",
              "      <th>auth_Dieter Roth</th>\n",
              "      <th>auth_Douglas Gordon</th>\n",
              "      <th>auth_Ed Ruscha</th>\n",
              "      <th>...</th>\n",
              "      <th>auth_Joseph Beuys</th>\n",
              "      <th>auth_Kader Attia</th>\n",
              "      <th>auth_Kiki Smith</th>\n",
              "      <th>auth_Lawrence Weiner</th>\n",
              "      <th>auth_Louise Bourgeois</th>\n",
              "      <th>auth_Lucio Fontana</th>\n",
              "      <th>auth_Man Ray</th>\n",
              "      <th>auth_Marcel Broodthaers</th>\n",
              "      <th>auth_Marcel Duchamp</th>\n",
              "      <th>auth_Maria Lassnig</th>\n",
              "      <th>auth_Marina Abramovic</th>\n",
              "      <th>auth_Marlene Dumas</th>\n",
              "      <th>auth_Martin Kippenberger</th>\n",
              "      <th>auth_Max Ernst</th>\n",
              "      <th>auth_Mike Kelley</th>\n",
              "      <th>auth_Mona Hatoum</th>\n",
              "      <th>auth_Nam June Paik</th>\n",
              "      <th>auth_Olafur Eliasson</th>\n",
              "      <th>auth_Pablo Picasso</th>\n",
              "      <th>auth_Paul Klee</th>\n",
              "      <th>auth_Paul McCarthy</th>\n",
              "      <th>auth_Pierre Huyghe</th>\n",
              "      <th>auth_Richard Long</th>\n",
              "      <th>auth_Richard Prince</th>\n",
              "      <th>auth_Richard Serra</th>\n",
              "      <th>auth_Rirkrit Tiravanija</th>\n",
              "      <th>auth_Robert Mapplethorpe</th>\n",
              "      <th>auth_Robert Rauschenberg</th>\n",
              "      <th>auth_Rosemarie Trockel</th>\n",
              "      <th>auth_Roy Lichtenstein</th>\n",
              "      <th>auth_Sigmar Polke</th>\n",
              "      <th>auth_Sol LeWitt</th>\n",
              "      <th>auth_Tacita Dean</th>\n",
              "      <th>auth_Thomas Ruff</th>\n",
              "      <th>auth_Thomas Schütte</th>\n",
              "      <th>auth_Tony Cragg</th>\n",
              "      <th>auth_Valie Export</th>\n",
              "      <th>auth_William Kentridge</th>\n",
              "      <th>auth_Yayoi Kusama</th>\n",
              "      <th>auth_Yoko Ono</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1964.0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>1500000.0</td>\n",
              "      <td>2000000.0</td>\n",
              "      <td>1150000.0</td>\n",
              "      <td>2019.0</td>\n",
              "      <td>images/Andy Warhol-Flowers-1-1.jpg</td>\n",
              "      <td>1928.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>51496.69</td>\n",
              "      <td>2153.0</td>\n",
              "      <td>8.7</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1985.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>60000.0</td>\n",
              "      <td>80000.0</td>\n",
              "      <td>50000.0</td>\n",
              "      <td>2019.0</td>\n",
              "      <td>images/Andy Warhol-Self-Defense (Negative)-1-3...</td>\n",
              "      <td>1928.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>51496.69</td>\n",
              "      <td>2153.0</td>\n",
              "      <td>8.7</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1983.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>50000.0</td>\n",
              "      <td>70000.0</td>\n",
              "      <td>70000.0</td>\n",
              "      <td>2019.0</td>\n",
              "      <td>images/Andy Warhol-Untitled (Four)-1-4.jpg</td>\n",
              "      <td>1928.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>51496.69</td>\n",
              "      <td>2153.0</td>\n",
              "      <td>8.7</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>1976.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>70000.0</td>\n",
              "      <td>100000.0</td>\n",
              "      <td>70000.0</td>\n",
              "      <td>2019.0</td>\n",
              "      <td>images/Andy Warhol-Torso-1-5.jpg</td>\n",
              "      <td>1928.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>51496.69</td>\n",
              "      <td>2153.0</td>\n",
              "      <td>8.7</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>1985.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>30000.0</td>\n",
              "      <td>50000.0</td>\n",
              "      <td>72000.0</td>\n",
              "      <td>2019.0</td>\n",
              "      <td>images/Andy Warhol-Are You \"Different?\" (Posit...</td>\n",
              "      <td>1928.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>51496.69</td>\n",
              "      <td>2153.0</td>\n",
              "      <td>8.7</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14699</th>\n",
              "      <td>1999.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>149320.0</td>\n",
              "      <td>223980.0</td>\n",
              "      <td>313572.0</td>\n",
              "      <td>2010.0</td>\n",
              "      <td>images/Marlene Dumas-Dancer-3-13.jpg</td>\n",
              "      <td>1953.0</td>\n",
              "      <td>114.0</td>\n",
              "      <td>14262.10</td>\n",
              "      <td>1011.0</td>\n",
              "      <td>3.6</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14700</th>\n",
              "      <td>1994.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>218820.0</td>\n",
              "      <td>281340.0</td>\n",
              "      <td>484530.0</td>\n",
              "      <td>2010.0</td>\n",
              "      <td>images/Marlene Dumas-\"The Peeping Tom \"-3-14.jpg</td>\n",
              "      <td>1953.0</td>\n",
              "      <td>114.0</td>\n",
              "      <td>14262.10</td>\n",
              "      <td>1011.0</td>\n",
              "      <td>3.6</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14701</th>\n",
              "      <td>1995.0</td>\n",
              "      <td>79.0</td>\n",
              "      <td>39.0</td>\n",
              "      <td>250000.0</td>\n",
              "      <td>350000.0</td>\n",
              "      <td>440000.0</td>\n",
              "      <td>2009.0</td>\n",
              "      <td>images/Marlene Dumas-Evil Eye-3-15.jpg</td>\n",
              "      <td>1953.0</td>\n",
              "      <td>98.0</td>\n",
              "      <td>14765.08</td>\n",
              "      <td>793.0</td>\n",
              "      <td>2.4</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14702</th>\n",
              "      <td>1996.0</td>\n",
              "      <td>49.0</td>\n",
              "      <td>27.0</td>\n",
              "      <td>70000.0</td>\n",
              "      <td>100000.0</td>\n",
              "      <td>60000.0</td>\n",
              "      <td>2009.0</td>\n",
              "      <td>images/Marlene Dumas-Transparent Slip-3-16.jpg</td>\n",
              "      <td>1953.0</td>\n",
              "      <td>98.0</td>\n",
              "      <td>14765.08</td>\n",
              "      <td>793.0</td>\n",
              "      <td>2.4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14703</th>\n",
              "      <td>1986.0</td>\n",
              "      <td>39.0</td>\n",
              "      <td>23.0</td>\n",
              "      <td>1133.0</td>\n",
              "      <td>1700.0</td>\n",
              "      <td>1077.0</td>\n",
              "      <td>2018.0</td>\n",
              "      <td>images/Pierre Huyghe-Sans titre double-face-1-...</td>\n",
              "      <td>1962.0</td>\n",
              "      <td>98.0</td>\n",
              "      <td>12992.24</td>\n",
              "      <td>2208.0</td>\n",
              "      <td>9.1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8559 rows × 106 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       creation_year  height(inch)  ...  auth_Yayoi Kusama  auth_Yoko Ono\n",
              "1             1964.0          22.0  ...                  0              0\n",
              "3             1985.0          20.0  ...                  0              0\n",
              "4             1983.0          20.0  ...                  0              0\n",
              "5             1976.0           8.0  ...                  0              0\n",
              "6             1985.0           8.0  ...                  0              0\n",
              "...              ...           ...  ...                ...            ...\n",
              "14699         1999.0           2.0  ...                  0              0\n",
              "14700         1994.0           2.0  ...                  0              0\n",
              "14701         1995.0          79.0  ...                  0              0\n",
              "14702         1996.0          49.0  ...                  0              0\n",
              "14703         1986.0          39.0  ...                  0              0\n",
              "\n",
              "[8559 rows x 106 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gIhK4kiewuOx",
        "colab_type": "code",
        "outputId": "d7f1b0f6-1aca-4f38-f540-ed46d2b0a660",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 915
        }
      },
      "source": [
        "# Pre-processing array to remove problematic rows. \n",
        "# images/François Morellet-Ligne droite-1-13.jpg\n",
        "\n",
        "#df[df['image'].str.contains('Morellet-Ligne droite-1-13')]\n",
        "df = df[~df['image'].str.contains(\"Morellet-Ligne droite-1-13\")]\n",
        "df"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>creation_year</th>\n",
              "      <th>height(inch)</th>\n",
              "      <th>width(inch)</th>\n",
              "      <th>estimate_low($)</th>\n",
              "      <th>estimate_high</th>\n",
              "      <th>hammer price</th>\n",
              "      <th>auction_year</th>\n",
              "      <th>image</th>\n",
              "      <th>artist_birth</th>\n",
              "      <th>artist_rank</th>\n",
              "      <th>artist_points</th>\n",
              "      <th>num_bill</th>\n",
              "      <th>wealth_bill</th>\n",
              "      <th>canvas</th>\n",
              "      <th>paper</th>\n",
              "      <th>Acrylic</th>\n",
              "      <th>Mixed media</th>\n",
              "      <th>oil</th>\n",
              "      <th>auth_Ai Weiwei</th>\n",
              "      <th>auth_Alberto Giacometti</th>\n",
              "      <th>auth_Alex Katz</th>\n",
              "      <th>auth_Alexander Calder</th>\n",
              "      <th>auth_Alighiero Boëtti</th>\n",
              "      <th>auth_Andy Warhol</th>\n",
              "      <th>auth_Anselm Kiefer</th>\n",
              "      <th>auth_Antoni Tàpies</th>\n",
              "      <th>auth_Arnulf Rainer</th>\n",
              "      <th>auth_Carl Andre</th>\n",
              "      <th>auth_Christian Boltanski</th>\n",
              "      <th>auth_Christian Marclay</th>\n",
              "      <th>auth_Cindy Sherman</th>\n",
              "      <th>auth_Claes Oldenburg</th>\n",
              "      <th>auth_Cy Twombly</th>\n",
              "      <th>auth_Damien Hirst</th>\n",
              "      <th>auth_Dan Graham</th>\n",
              "      <th>auth_Daniel Buren</th>\n",
              "      <th>auth_David Hockney</th>\n",
              "      <th>auth_Dieter Roth</th>\n",
              "      <th>auth_Douglas Gordon</th>\n",
              "      <th>auth_Ed Ruscha</th>\n",
              "      <th>...</th>\n",
              "      <th>auth_Joseph Beuys</th>\n",
              "      <th>auth_Kader Attia</th>\n",
              "      <th>auth_Kiki Smith</th>\n",
              "      <th>auth_Lawrence Weiner</th>\n",
              "      <th>auth_Louise Bourgeois</th>\n",
              "      <th>auth_Lucio Fontana</th>\n",
              "      <th>auth_Man Ray</th>\n",
              "      <th>auth_Marcel Broodthaers</th>\n",
              "      <th>auth_Marcel Duchamp</th>\n",
              "      <th>auth_Maria Lassnig</th>\n",
              "      <th>auth_Marina Abramovic</th>\n",
              "      <th>auth_Marlene Dumas</th>\n",
              "      <th>auth_Martin Kippenberger</th>\n",
              "      <th>auth_Max Ernst</th>\n",
              "      <th>auth_Mike Kelley</th>\n",
              "      <th>auth_Mona Hatoum</th>\n",
              "      <th>auth_Nam June Paik</th>\n",
              "      <th>auth_Olafur Eliasson</th>\n",
              "      <th>auth_Pablo Picasso</th>\n",
              "      <th>auth_Paul Klee</th>\n",
              "      <th>auth_Paul McCarthy</th>\n",
              "      <th>auth_Pierre Huyghe</th>\n",
              "      <th>auth_Richard Long</th>\n",
              "      <th>auth_Richard Prince</th>\n",
              "      <th>auth_Richard Serra</th>\n",
              "      <th>auth_Rirkrit Tiravanija</th>\n",
              "      <th>auth_Robert Mapplethorpe</th>\n",
              "      <th>auth_Robert Rauschenberg</th>\n",
              "      <th>auth_Rosemarie Trockel</th>\n",
              "      <th>auth_Roy Lichtenstein</th>\n",
              "      <th>auth_Sigmar Polke</th>\n",
              "      <th>auth_Sol LeWitt</th>\n",
              "      <th>auth_Tacita Dean</th>\n",
              "      <th>auth_Thomas Ruff</th>\n",
              "      <th>auth_Thomas Schütte</th>\n",
              "      <th>auth_Tony Cragg</th>\n",
              "      <th>auth_Valie Export</th>\n",
              "      <th>auth_William Kentridge</th>\n",
              "      <th>auth_Yayoi Kusama</th>\n",
              "      <th>auth_Yoko Ono</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1964.0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>1500000.0</td>\n",
              "      <td>2000000.0</td>\n",
              "      <td>1150000.0</td>\n",
              "      <td>2019.0</td>\n",
              "      <td>images/Andy Warhol-Flowers-1-1.jpg</td>\n",
              "      <td>1928.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>51496.69</td>\n",
              "      <td>2153.0</td>\n",
              "      <td>8.7</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1985.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>60000.0</td>\n",
              "      <td>80000.0</td>\n",
              "      <td>50000.0</td>\n",
              "      <td>2019.0</td>\n",
              "      <td>images/Andy Warhol-Self-Defense (Negative)-1-3...</td>\n",
              "      <td>1928.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>51496.69</td>\n",
              "      <td>2153.0</td>\n",
              "      <td>8.7</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1983.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>50000.0</td>\n",
              "      <td>70000.0</td>\n",
              "      <td>70000.0</td>\n",
              "      <td>2019.0</td>\n",
              "      <td>images/Andy Warhol-Untitled (Four)-1-4.jpg</td>\n",
              "      <td>1928.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>51496.69</td>\n",
              "      <td>2153.0</td>\n",
              "      <td>8.7</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>1976.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>70000.0</td>\n",
              "      <td>100000.0</td>\n",
              "      <td>70000.0</td>\n",
              "      <td>2019.0</td>\n",
              "      <td>images/Andy Warhol-Torso-1-5.jpg</td>\n",
              "      <td>1928.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>51496.69</td>\n",
              "      <td>2153.0</td>\n",
              "      <td>8.7</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>1985.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>30000.0</td>\n",
              "      <td>50000.0</td>\n",
              "      <td>72000.0</td>\n",
              "      <td>2019.0</td>\n",
              "      <td>images/Andy Warhol-Are You \"Different?\" (Posit...</td>\n",
              "      <td>1928.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>51496.69</td>\n",
              "      <td>2153.0</td>\n",
              "      <td>8.7</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14699</th>\n",
              "      <td>1999.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>149320.0</td>\n",
              "      <td>223980.0</td>\n",
              "      <td>313572.0</td>\n",
              "      <td>2010.0</td>\n",
              "      <td>images/Marlene Dumas-Dancer-3-13.jpg</td>\n",
              "      <td>1953.0</td>\n",
              "      <td>114.0</td>\n",
              "      <td>14262.10</td>\n",
              "      <td>1011.0</td>\n",
              "      <td>3.6</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14700</th>\n",
              "      <td>1994.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>218820.0</td>\n",
              "      <td>281340.0</td>\n",
              "      <td>484530.0</td>\n",
              "      <td>2010.0</td>\n",
              "      <td>images/Marlene Dumas-\"The Peeping Tom \"-3-14.jpg</td>\n",
              "      <td>1953.0</td>\n",
              "      <td>114.0</td>\n",
              "      <td>14262.10</td>\n",
              "      <td>1011.0</td>\n",
              "      <td>3.6</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14701</th>\n",
              "      <td>1995.0</td>\n",
              "      <td>79.0</td>\n",
              "      <td>39.0</td>\n",
              "      <td>250000.0</td>\n",
              "      <td>350000.0</td>\n",
              "      <td>440000.0</td>\n",
              "      <td>2009.0</td>\n",
              "      <td>images/Marlene Dumas-Evil Eye-3-15.jpg</td>\n",
              "      <td>1953.0</td>\n",
              "      <td>98.0</td>\n",
              "      <td>14765.08</td>\n",
              "      <td>793.0</td>\n",
              "      <td>2.4</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14702</th>\n",
              "      <td>1996.0</td>\n",
              "      <td>49.0</td>\n",
              "      <td>27.0</td>\n",
              "      <td>70000.0</td>\n",
              "      <td>100000.0</td>\n",
              "      <td>60000.0</td>\n",
              "      <td>2009.0</td>\n",
              "      <td>images/Marlene Dumas-Transparent Slip-3-16.jpg</td>\n",
              "      <td>1953.0</td>\n",
              "      <td>98.0</td>\n",
              "      <td>14765.08</td>\n",
              "      <td>793.0</td>\n",
              "      <td>2.4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14703</th>\n",
              "      <td>1986.0</td>\n",
              "      <td>39.0</td>\n",
              "      <td>23.0</td>\n",
              "      <td>1133.0</td>\n",
              "      <td>1700.0</td>\n",
              "      <td>1077.0</td>\n",
              "      <td>2018.0</td>\n",
              "      <td>images/Pierre Huyghe-Sans titre double-face-1-...</td>\n",
              "      <td>1962.0</td>\n",
              "      <td>98.0</td>\n",
              "      <td>12992.24</td>\n",
              "      <td>2208.0</td>\n",
              "      <td>9.1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8558 rows × 106 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       creation_year  height(inch)  ...  auth_Yayoi Kusama  auth_Yoko Ono\n",
              "1             1964.0          22.0  ...                  0              0\n",
              "3             1985.0          20.0  ...                  0              0\n",
              "4             1983.0          20.0  ...                  0              0\n",
              "5             1976.0           8.0  ...                  0              0\n",
              "6             1985.0           8.0  ...                  0              0\n",
              "...              ...           ...  ...                ...            ...\n",
              "14699         1999.0           2.0  ...                  0              0\n",
              "14700         1994.0           2.0  ...                  0              0\n",
              "14701         1995.0          79.0  ...                  0              0\n",
              "14702         1996.0          49.0  ...                  0              0\n",
              "14703         1986.0          39.0  ...                  0              0\n",
              "\n",
              "[8558 rows x 106 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qRER55fhXrt_",
        "colab_type": "code",
        "outputId": "12d59f22-9319-4cfa-f85e-970e3c6f3c57",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 328
        }
      },
      "source": [
        "#check distribution of hammer price\n",
        "df.hist(column='hammer price', bins=100)\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[<matplotlib.axes._subplots.AxesSubplot object at 0x7f50c0653c88>]],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAEVCAYAAAAM3jVmAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Xy4E5YFWhSt",
        "colab_type": "code",
        "outputId": "133ac9bc-2b44-480f-a9b3-c4130054b3fc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        }
      },
      "source": [
        "#create log hammer price\n",
        "df['log hammer price'] = np.log10(df['hammer price'])\n",
        "df.hist(column='log hammer price', bins=100)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[<matplotlib.axes._subplots.AxesSubplot object at 0x7f50b5ef2198>]],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAEICAYAAACktLTqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAWa0lEQVR4nO3df7RlZX3f8fdHMYoM5ccCb8ZhwthK\nXFFnBfUuNDXNulM0IvmBtg3VUMv4o2NbtFppIlrb2EZaulYwxmVDO4qCVbkhoJUiqEidpaYhOkOI\nww9dQR2EEQdjYGCQmg5++8fZMx7Ge+f+OOfMOfeZ92uts+7e+9l7n+c5Pz73Oc/eZ59UFZKktjxu\n3BWQJA2f4S5JDTLcJalBhrskNchwl6QGGe6S1CDDXUOVZEeSF41gv1uSvG7Y+12Jkvy9JF8fdz00\n2Y4YdwUkLU1VfRF4xrjroclmz106RNIz0HsuiR0yLYrhrpFJ8sQk70nyne72niRP7Cv/7ST3dmWv\nS1JJnn6QXZ6c5E+SPJTks0lO6NvXHyf5bpLdSb6Q5Fl9ZZcl+cMk1yfZ0+3jp7v63J/ka0me07f+\njiS/leSrSR5OcmmSqW77h5J8Lslxfeu/IMn/SfJAkr9IMtNXtiXJhUn+BPgB8LfneJx2JHlbktu7\n+nwoyZO6spkk9yR5a5LvAh/at6xv+7VJPp7ke0m+n+R9fWWvSXJHt9/PJDl5UU+eVjzDXaP0b4EX\nAKcCPw+cBrwDIMkZwFuAFwFPB2YWsb/fBF4NPAX4KeDf9JVdD5zSld0MfPSAbc/u7vsE4IfAn3br\nnQBcBbz7gPX/IfBi4GeBX+v2/3bgRHrvm3/VtWMN8CngXcDxXZ2uTnJi375eBWwCjgbumqdt5wAv\nAf5Od5/v6Cv76W7fJ3f72S/J44Fru/2uA9YAs13ZWV2d/0FX7y8CV8xz/2pNVXnzNrQbsAN4UTf9\nDeDMvrKXADu66Q8C/7mv7OlAAU+fZ79bgHf0zf9L4NPzrHtst69juvnLgPf3lb8RuKNvfj3wwAFt\nOKdv/mrgkgO2/5/d9FuB/3HA/X8GOLev3v9xEY/ZP++bPxP4Rjc9A/wN8KS+8hngnm76F4DvAUfM\nsd/rgdf2zT+O3qeHk8f9OvE2+ps9d43SU3lsT/Wubtm+srv7yvqn5/PdvukfAKug13tNclGSbyR5\nkF5YQq9Xvs+uvulH5phfdcB9LXb9k4Hf6IZkHkjyAPCLwOq+9RfTtv51+h8ngO9V1f+dZ7u1wF1V\ntXeOspOBP+ir118Dode7V+M8OKNR+g69gLmtm/+ZbhnAvcBJfeuuHeB+fhM4i94Qzw7gGOB+ekE2\nanfT67n/s4Oss5hLr/a3v/9xWmj7u4GfSXLEHAF/N3BhVR04RKXDgD13jdIVwDuSnNgd/Pz3wEe6\nsiuBVyf5uSRPBv7dAPdzNL1x9O8DTwb+0wD7WqqPAL+W5CXdJ4gndQc8T1pwy8c6L8lJSY6nd6zi\njxa53Zfp/aO8KMlR3f2/sCv7b8Db9h1cTnJMkt9YYr20QhnuGqV3AVuBrwLb6R3AfBdAVV0PvBf4\nPHAncFO3zQ+XcT8fpjeUsRO4vW9fI1dVd9P71PB2emPfdwO/xdLfWx8DPgt8k96xinct8v4fpXfA\n9+nAt4F7gH/clX0C+C/AbDdcdSvw0iXWSytUqvyxDo1fkp+jFz5PnGf8uFlJdgCvq6rPjbsuaoc9\nd41Nkpd358IfR6+H+b8Ot2CXRsVw1zi9HriP3jDEo8C/GG91pHY4LCNJDbLnLkkNmojz3E844YRa\nt27d/vmHH36Yo446anwVGpEW29Vim6DNdrXYJji827Vt27a/qqoT5yqbiHBft24dW7du3T+/ZcsW\nZmZmxlehEWmxXS22CdpsV4ttgsO7XUnmu1aRwzKS1CLDXZIaZLhLUoMMd0lqkOEuSQ0y3CWpQYa7\nJDXIcJekBhnuktSgifiGqrTSrbvgU/und1z0K2OsidRjz12SGmS4S1KDDHdJapBj7tIIORavcVmw\n555kbZLPJ7k9yW1J3tQtf2eSnUlu6W5n9m3ztiR3Jvl6kpeMsgGSpJ+0mJ77XuD8qro5ydHAtiQ3\ndGW/X1W/179ykmcCrwCeBTwV+FySn62qR4dZcUnS/BbsuVfVvVV1czf9EHAHsOYgm5wFzFbVD6vq\nW8CdwGnDqKwkaXGW9APZSdYBXwCeDbwF2Ag8CGyl17u/P8n7gJuq6iPdNpcC11fVVQfsaxOwCWBq\naup5s7Oz+8v27NnDqlWrlt2oSdViu1psE8zfru07d++fXr/mmGUvH4fD7bla6RbTrg0bNmyrqum5\nyhZ9QDXJKuBq4M1V9WCSS4DfBar7ezHwmsXur6o2A5sBpqenq//npA7nn81aaVpsE8zfro39B0jP\nmVn28nE43J6rlW7Qdi3qVMgkT6AX7B+tqo8DVNWuqnq0qn4EvJ8fD73sBNb2bX5St0ySdIgs2HNP\nEuBS4I6qenff8tVVdW83+3Lg1m76GuBjSd5N74DqKcCXh1praYXzFEmN2mKGZV4IvArYnuSWbtnb\ngVcmOZXesMwO4PUAVXVbkiuB2+mdaXOeZ8pI0qG1YLhX1ZeAzFF03UG2uRC4cIB6SZIG4OUHJKlB\nhrskNchwl6QGGe6S1CDDXZIaZLhLUoMMd0lqkD/WIR0i/d9KlUbNnrskNchwl6QGGe6S1CDDXZIa\n5AFVaZk8QKpJZrireYf62umGviaBwzKS1CDDXZIa5LCMNKH8KT4NwnCX5rB95242duE6CcFq0Gup\nDHc1wwCUfswxd0lqkOEuSQ0y3CWpQYa7JDXIcJekBhnuktQgw12SGmS4S1KD/BKTtML4ZS0thj13\nSWqQ4S5JDXJYRhPL4Qdp+RbsuSdZm+TzSW5PcluSN3XLj09yQ5K/7P4e1y1PkvcmuTPJV5M8d9SN\nkCQ91mJ67nuB86vq5iRHA9uS3ABsBG6sqouSXABcALwVeClwSnd7PnBJ91dakfzZPK1EC4Z7Vd0L\n3NtNP5TkDmANcBYw0612ObCFXrifBXy4qgq4KcmxSVZ3+5HG6mBDPf1l568/ZFWSRiK9DF7kysk6\n4AvAs4FvV9Wx3fIA91fVsUmuBS6qqi91ZTcCb62qrQfsaxOwCWBqaup5s7Oz+8v27NnDqlWrBmjW\nZGqxXaNs0/adu/dPr19zzLLX71/e78B99q83dSTsemTRVR3IfG2br96L2XYuLb7+4PBu14YNG7ZV\n1fRcZYs+oJpkFXA18OaqerCX5z1VVUkW/1+it81mYDPA9PR0zczM7C/bsmUL/fOtaLFdo2zTxv5e\n9jkL38d862+cZ1jlwH1ufEzPfS8Xbz9E5xtsf/jHder7NDFfvfst5nHZp8XXH9iu+Szq1ZvkCfSC\n/aNV9fFu8a59wy1JVgP3dct3Amv7Nj+pWyZNFMfS1bLFnC0T4FLgjqp6d1/RNcC53fS5wCf7lv/T\n7qyZFwC7HW+XpENrMT33FwKvArYnuaVb9nbgIuDKJK8F7gLO7squA84E7gR+ALx6qDWWJC1oMWfL\nfAnIPMWnz7F+AecNWC9J0gC8/IAkNchwl6QGGe6S1CDDXZIa5FUhpQniufcaFnvuktQgw12SGmS4\nS1KDDHdJapDhLkkNMtwlqUGGuyQ1yPPc1aTD5Xzxg/1soA5v9twlqUH23LXi2FuVFma4a0U7XIZf\npKVyWEaSGmTPXWqEw1XqZ89dkhpkuEtSgwx3SWqQ4S5JDTLcJalBhrskNchwl6QGGe6S1CC/xKSJ\nMt/lBLzMgLQ09twlqUGGuyQ1yHCXpAYZ7pLUoAXDPckHk9yX5Na+Ze9MsjPJLd3tzL6ytyW5M8nX\nk7xkVBWXJM1vMT33y4Az5lj++1V1ane7DiDJM4FXAM/qtvnDJI8fVmUlSYuz4KmQVfWFJOsWub+z\ngNmq+iHwrSR3AqcBf7rsGqpJXntcGq1U1cIr9cL92qp6djf/TmAj8CCwFTi/qu5P8j7gpqr6SLfe\npcD1VXXVHPvcBGwCmJqaet7s7Oz+sj179rBq1apB2jWRWmzXctu0fefu/dPr1xwz5/JxmjoSdj0y\n7losX/9juk+Lrz84vNu1YcOGbVU1PVfZcr/EdAnwu0B1fy8GXrOUHVTVZmAzwPT0dM3MzOwv27Jl\nC/3zrWixXctt08b+nvs5M3MuH6fz1+/l4u0r9zt+/Y/pPi2+/sB2zWdZZ8tU1a6qerSqfgS8n97Q\nC8BOYG3fqid1yyRJh9Cywj3J6r7ZlwP7zqS5BnhFkicmeRpwCvDlwaooSVqqBT93JrkCmAFOSHIP\n8DvATJJT6Q3L7ABeD1BVtyW5Ergd2AucV1WPjqbqWmm8Pox06CzmbJlXzrH40oOsfyFw4SCVkiQN\nxm+oSlKDDHdJapDhLkkNMtwlqUGGuyQ1yHCXpAYZ7pLUIMNdkhpkuEtSgwx3SWqQ4S5JDTLcJalB\nhrskNchwl6QGrdzfEZM0L3+AXIa7xs4f8ZCGz2EZSWqQ4S5JDXJYRmrcvmGv89fvZWa8VdEhZM9d\nkhpkuEtSgwx3SWqQ4S5JDTLcJalBhrskNchwl6QGeZ67RspLC0jjYbhLhykvLtY2h2UkqUH23DUU\n9gKlybJgzz3JB5Pcl+TWvmXHJ7khyV92f4/rlifJe5PcmeSrSZ47ysprvNZd8Cm279ztuLo0gRYz\nLHMZcMYByy4AbqyqU4Abu3mAlwKndLdNwCXDqaYkaSkWDPeq+gLw1wcsPgu4vJu+HHhZ3/IPV89N\nwLFJVg+rspKkxUlVLbxSsg64tqqe3c0/UFXHdtMB7q+qY5NcC1xUVV/qym4E3lpVW+fY5yZ6vXum\npqaeNzs7u79sz549rFq1asCmTZ7W2rV9526mjoRdjzx2+fo1xzxmnZVornatdFNHwlOOn/u56X/O\nVprW3lf7LKZdGzZs2FZV03OVDXxAtaoqycL/IX5yu83AZoDp6emamZnZX7Zlyxb651vRWrs2XvAp\nzl+/l4u3P/ZltOOcmcessxLN1a6V7vz1ezm77/XX/9z0P2crTWvvq30GbddyX727kqyuqnu7YZf7\nuuU7gbV9653ULdNhxAOs0vgtN9yvAc4FLur+frJv+RuSzALPB3ZX1b0D11Jj5WmO7fM5bs+C4Z7k\nCmAGOCHJPcDv0Av1K5O8FrgLOLtb/TrgTOBO4AfAq0dQZ0nSAhYM96p65TxFp8+xbgHnDVopSdJg\n2jpiJOmgPB5y+PDaMpLUIHvuWhJ7ftLKYM9dkhpkuEtSgwx3SWqQ4S5JDTLcJalBhrskNchwl6QG\neZ675uT57NLKZs9dkhpkuEtSgwx3SWqQY+6SHuPA4y3+eMfKZM9dkhpkuEtSgxyWOcz525laLl87\nk82euyQ1yJ67pIHZi588hrukoTLoJ4PhLumgDOuVyTF3SWqQ4S5JDTLcJalBhrskNcgDqpJGxoOx\n42O4az9/oENqh8MyktQge+6SFs1PdyuH4d4oxzqlw9tA4Z5kB/AQ8Ciwt6qmkxwP/BGwDtgBnF1V\n9w9WTQ2TvS+pfcMYc99QVadW1XQ3fwFwY1WdAtzYzUuSDqFRHFA9C7i8m74ceNkI7kOSdBCpquVv\nnHwLuB8o4L9X1eYkD1TVsV15gPv3zR+w7SZgE8DU1NTzZmdn95ft2bOHVatWLbtek+pQtmv7zt37\np9evOWbeskFNHQm7Hhna7iZGi+0ad5sOfB0Oy+GcFxs2bNjWN2ryGIOG+5qq2pnkKcANwBuBa/rD\nPMn9VXXcwfYzPT1dW7du3T+/ZcsWZmZmll2vSXUo23WwA6rDHHM/f/1eLt7e3nH5Fts17jaN6sD+\n4ZwXSeYN94GGZapqZ/f3PuATwGnAriSruzteDdw3yH1IkpZu2eGe5KgkR++bBn4ZuBW4Bji3W+1c\n4JODVlKStDSDfEabAj7RG1bnCOBjVfXpJF8BrkzyWuAu4OzBq6nF8BRHTTK/e3FoLTvcq+qbwM/P\nsfz7wOmDVEqSNBivLSNJDTLcJalBbZ3rpTk5Fq9J5lj8aBjuK4RvAElL4bCMJDXIcJekBhnuktQg\nw12SGuQB1RXIs18kLcSeuyQ1yJ77hPGUR0nDYLhLOuTmG1q0czM8hrukiWTQD8Yxd0lqkOEuSQ0y\n3CWpQYa7JDXIA6qSJp4HV5fOnrskNchwl6QGOSwjaUVxiGZx7LlLUoMMd0lqkMMyE2Ax19mQ9JPW\nXfApzl+/l40HvFccrrHnLklNMtwlqUGGuyQ1yDF3SU1bzLGrFsfoDfcR639hXXbGUXMulzRcg7y/\nWjmP3nBfhKU+2fO9sLbv3P0TR/UlaRQMd0mHveX09Ce9hz+ycE9yBvAHwOOBD1TVRaO6r1FY6pPt\nMIvUnpUc+iMJ9ySPB/4r8GLgHuArSa6pqtuHfV8He/BH8cBOyhMnSQczqp77acCdVfVNgCSzwFnA\n0MN9OeYLaHvrkkZlvrwYVScxVTX8nSb/CDijql7Xzb8KeH5VvaFvnU3Apm72GcDX+3ZxAvBXQ6/Y\n+LXYrhbbBG22q8U2weHdrpOr6sS5CsZ2QLWqNgOb5ypLsrWqpg9xlUauxXa12CZos10ttgls13xG\n9Q3VncDavvmTumWSpENgVOH+FeCUJE9L8lPAK4BrRnRfkqQDjGRYpqr2JnkD8Bl6p0J+sKpuW8Iu\n5hyuaUCL7WqxTdBmu1psE9iuOY3kgKokaby8KqQkNchwl6QGTVS4J1mb5PNJbk9yW5I3jbtOg0ry\npCRfTvIXXZv+w7jrNExJHp/kz5NcO+66DEuSHUm2J7klydZx12cYkhyb5KokX0tyR5JfGHedBpXk\nGd1ztO/2YJI3j7teg0ryr7usuDXJFUmetKz9TNKYe5LVwOqqujnJ0cA24GWjuGzBoZIkwFFVtSfJ\nE4AvAW+qqpvGXLWhSPIWYBr4W1X1q+OuzzAk2QFMV1UzX4xJcjnwxar6QHcG25Or6oFx12tYukue\n7KT3Zcm7xl2f5Uqyhl5GPLOqHklyJXBdVV221H1NVM+9qu6tqpu76YeAO4A1463VYKpnTzf7hO42\nOf9RB5DkJOBXgA+Muy6aX5JjgF8CLgWoqr9pKdg7pwPfWMnB3ucI4MgkRwBPBr6znJ1MVLj3S7IO\neA7wZ+OtyeC6oYtbgPuAG6pqxbep8x7gt4EfjbsiQ1bAZ5Ns6y6TsdI9Dfge8KFuCO0DSY5aaKMV\n5hXAFeOuxKCqaifwe8C3gXuB3VX12eXsayLDPckq4GrgzVX14LjrM6iqerSqTqX3Td3Tkjx73HUa\nVJJfBe6rqm3jrssI/GJVPRd4KXBekl8ad4UGdATwXOCSqnoO8DBwwXirNDzdMNOvA3887roMKslx\n9C6y+DTgqcBRSf7JcvY1ceHejUtfDXy0qj4+7voMU/dR+PPAGeOuyxC8EPj1bnx6Fvj7ST4y3ioN\nR9d7oqruAz5B7yqnK9k9wD19nxivohf2rXgpcHNV7Rp3RYbgRcC3qup7VfX/gI8Df3c5O5qocO8O\nPl4K3FFV7x53fYYhyYlJju2mj6R3jfuvjbdWg6uqt1XVSVW1jt5H4v9dVcvqYUySJEd1B/Pphi5+\nGbh1vLUaTFV9F7g7yTO6RaczIZffHpJX0sCQTOfbwAuSPLnLw9PpHXtcskn7mb0XAq8Ctndj1ABv\nr6rrxlinQa0GLu+O5j8OuLKqmjltsEFTwCd67yuOAD5WVZ8eb5WG4o3AR7shjG8Crx5zfYai+wf8\nYuD1467LMFTVnyW5CrgZ2Av8Ocu8DMFEnQopSRqOiRqWkSQNh+EuSQ0y3CWpQYa7JDXIcJekBhnu\nktQgw12SGvT/AYbvwef5gY2JAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K7zDpOLLyzUv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#drop 'hammer price' column\n",
        "df = df.drop(columns='hammer price')\n",
        "df['image'].replace({'\\n':' '},inplace=True,regex=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ATx94FXNWhaV",
        "colab_type": "code",
        "outputId": "cf28a514-a2f6-4cc9-a840-71127337170a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        }
      },
      "source": [
        "#bin log hammer price\n",
        "bins = [0,3,3.25,3.5, 3.75, 4,4.25,4.5,4.75, 5,5.25, 5.5,5.75,6,6.25,6.5,6.75,7,7.25,7.5,7.75,8]\n",
        "labels = [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20]\n",
        "df['binned'] = pd.cut(df['log hammer price'], bins=bins, labels=labels)\n",
        "print(df)\n",
        "df.shape\n",
        "len(labels)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "       creation_year  height(inch)  ...  log hammer price  binned\n",
            "1             1964.0          22.0  ...          6.060698      13\n",
            "3             1985.0          20.0  ...          4.698970       7\n",
            "4             1983.0          20.0  ...          4.845098       8\n",
            "5             1976.0           8.0  ...          4.845098       8\n",
            "6             1985.0           8.0  ...          4.857332       8\n",
            "...              ...           ...  ...               ...     ...\n",
            "14699         1999.0           2.0  ...          5.496337      10\n",
            "14700         1994.0           2.0  ...          5.685321      11\n",
            "14701         1995.0          79.0  ...          5.643453      11\n",
            "14702         1996.0          49.0  ...          4.778151       8\n",
            "14703         1986.0          39.0  ...          3.032216       1\n",
            "\n",
            "[8558 rows x 107 columns]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "21"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j8NLUKrGLIjK",
        "colab_type": "code",
        "outputId": "134a62e6-6ed3-4d2a-9ca9-59c006f64435",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 915
        }
      },
      "source": [
        "df"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>creation_year</th>\n",
              "      <th>height(inch)</th>\n",
              "      <th>width(inch)</th>\n",
              "      <th>estimate_low($)</th>\n",
              "      <th>estimate_high</th>\n",
              "      <th>auction_year</th>\n",
              "      <th>image</th>\n",
              "      <th>artist_birth</th>\n",
              "      <th>artist_rank</th>\n",
              "      <th>artist_points</th>\n",
              "      <th>num_bill</th>\n",
              "      <th>wealth_bill</th>\n",
              "      <th>canvas</th>\n",
              "      <th>paper</th>\n",
              "      <th>Acrylic</th>\n",
              "      <th>Mixed media</th>\n",
              "      <th>oil</th>\n",
              "      <th>auth_Ai Weiwei</th>\n",
              "      <th>auth_Alberto Giacometti</th>\n",
              "      <th>auth_Alex Katz</th>\n",
              "      <th>auth_Alexander Calder</th>\n",
              "      <th>auth_Alighiero Boëtti</th>\n",
              "      <th>auth_Andy Warhol</th>\n",
              "      <th>auth_Anselm Kiefer</th>\n",
              "      <th>auth_Antoni Tàpies</th>\n",
              "      <th>auth_Arnulf Rainer</th>\n",
              "      <th>auth_Carl Andre</th>\n",
              "      <th>auth_Christian Boltanski</th>\n",
              "      <th>auth_Christian Marclay</th>\n",
              "      <th>auth_Cindy Sherman</th>\n",
              "      <th>auth_Claes Oldenburg</th>\n",
              "      <th>auth_Cy Twombly</th>\n",
              "      <th>auth_Damien Hirst</th>\n",
              "      <th>auth_Dan Graham</th>\n",
              "      <th>auth_Daniel Buren</th>\n",
              "      <th>auth_David Hockney</th>\n",
              "      <th>auth_Dieter Roth</th>\n",
              "      <th>auth_Douglas Gordon</th>\n",
              "      <th>auth_Ed Ruscha</th>\n",
              "      <th>auth_Erwin Wurm</th>\n",
              "      <th>...</th>\n",
              "      <th>auth_Kiki Smith</th>\n",
              "      <th>auth_Lawrence Weiner</th>\n",
              "      <th>auth_Louise Bourgeois</th>\n",
              "      <th>auth_Lucio Fontana</th>\n",
              "      <th>auth_Man Ray</th>\n",
              "      <th>auth_Marcel Broodthaers</th>\n",
              "      <th>auth_Marcel Duchamp</th>\n",
              "      <th>auth_Maria Lassnig</th>\n",
              "      <th>auth_Marina Abramovic</th>\n",
              "      <th>auth_Marlene Dumas</th>\n",
              "      <th>auth_Martin Kippenberger</th>\n",
              "      <th>auth_Max Ernst</th>\n",
              "      <th>auth_Mike Kelley</th>\n",
              "      <th>auth_Mona Hatoum</th>\n",
              "      <th>auth_Nam June Paik</th>\n",
              "      <th>auth_Olafur Eliasson</th>\n",
              "      <th>auth_Pablo Picasso</th>\n",
              "      <th>auth_Paul Klee</th>\n",
              "      <th>auth_Paul McCarthy</th>\n",
              "      <th>auth_Pierre Huyghe</th>\n",
              "      <th>auth_Richard Long</th>\n",
              "      <th>auth_Richard Prince</th>\n",
              "      <th>auth_Richard Serra</th>\n",
              "      <th>auth_Rirkrit Tiravanija</th>\n",
              "      <th>auth_Robert Mapplethorpe</th>\n",
              "      <th>auth_Robert Rauschenberg</th>\n",
              "      <th>auth_Rosemarie Trockel</th>\n",
              "      <th>auth_Roy Lichtenstein</th>\n",
              "      <th>auth_Sigmar Polke</th>\n",
              "      <th>auth_Sol LeWitt</th>\n",
              "      <th>auth_Tacita Dean</th>\n",
              "      <th>auth_Thomas Ruff</th>\n",
              "      <th>auth_Thomas Schütte</th>\n",
              "      <th>auth_Tony Cragg</th>\n",
              "      <th>auth_Valie Export</th>\n",
              "      <th>auth_William Kentridge</th>\n",
              "      <th>auth_Yayoi Kusama</th>\n",
              "      <th>auth_Yoko Ono</th>\n",
              "      <th>log hammer price</th>\n",
              "      <th>binned</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1964.0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>1500000.0</td>\n",
              "      <td>2000000.0</td>\n",
              "      <td>2019.0</td>\n",
              "      <td>images/Andy Warhol-Flowers-1-1.jpg</td>\n",
              "      <td>1928.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>51496.69</td>\n",
              "      <td>2153.0</td>\n",
              "      <td>8.7</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>6.060698</td>\n",
              "      <td>13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1985.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>60000.0</td>\n",
              "      <td>80000.0</td>\n",
              "      <td>2019.0</td>\n",
              "      <td>images/Andy Warhol-Self-Defense (Negative)-1-3...</td>\n",
              "      <td>1928.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>51496.69</td>\n",
              "      <td>2153.0</td>\n",
              "      <td>8.7</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4.698970</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1983.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>50000.0</td>\n",
              "      <td>70000.0</td>\n",
              "      <td>2019.0</td>\n",
              "      <td>images/Andy Warhol-Untitled (Four)-1-4.jpg</td>\n",
              "      <td>1928.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>51496.69</td>\n",
              "      <td>2153.0</td>\n",
              "      <td>8.7</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4.845098</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>1976.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>70000.0</td>\n",
              "      <td>100000.0</td>\n",
              "      <td>2019.0</td>\n",
              "      <td>images/Andy Warhol-Torso-1-5.jpg</td>\n",
              "      <td>1928.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>51496.69</td>\n",
              "      <td>2153.0</td>\n",
              "      <td>8.7</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4.845098</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>1985.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>30000.0</td>\n",
              "      <td>50000.0</td>\n",
              "      <td>2019.0</td>\n",
              "      <td>images/Andy Warhol-Are You \"Different?\" (Posit...</td>\n",
              "      <td>1928.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>51496.69</td>\n",
              "      <td>2153.0</td>\n",
              "      <td>8.7</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4.857332</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14699</th>\n",
              "      <td>1999.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>149320.0</td>\n",
              "      <td>223980.0</td>\n",
              "      <td>2010.0</td>\n",
              "      <td>images/Marlene Dumas-Dancer-3-13.jpg</td>\n",
              "      <td>1953.0</td>\n",
              "      <td>114.0</td>\n",
              "      <td>14262.10</td>\n",
              "      <td>1011.0</td>\n",
              "      <td>3.6</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5.496337</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14700</th>\n",
              "      <td>1994.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>218820.0</td>\n",
              "      <td>281340.0</td>\n",
              "      <td>2010.0</td>\n",
              "      <td>images/Marlene Dumas-\"The Peeping Tom \"-3-14.jpg</td>\n",
              "      <td>1953.0</td>\n",
              "      <td>114.0</td>\n",
              "      <td>14262.10</td>\n",
              "      <td>1011.0</td>\n",
              "      <td>3.6</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5.685321</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14701</th>\n",
              "      <td>1995.0</td>\n",
              "      <td>79.0</td>\n",
              "      <td>39.0</td>\n",
              "      <td>250000.0</td>\n",
              "      <td>350000.0</td>\n",
              "      <td>2009.0</td>\n",
              "      <td>images/Marlene Dumas-Evil Eye-3-15.jpg</td>\n",
              "      <td>1953.0</td>\n",
              "      <td>98.0</td>\n",
              "      <td>14765.08</td>\n",
              "      <td>793.0</td>\n",
              "      <td>2.4</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5.643453</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14702</th>\n",
              "      <td>1996.0</td>\n",
              "      <td>49.0</td>\n",
              "      <td>27.0</td>\n",
              "      <td>70000.0</td>\n",
              "      <td>100000.0</td>\n",
              "      <td>2009.0</td>\n",
              "      <td>images/Marlene Dumas-Transparent Slip-3-16.jpg</td>\n",
              "      <td>1953.0</td>\n",
              "      <td>98.0</td>\n",
              "      <td>14765.08</td>\n",
              "      <td>793.0</td>\n",
              "      <td>2.4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4.778151</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14703</th>\n",
              "      <td>1986.0</td>\n",
              "      <td>39.0</td>\n",
              "      <td>23.0</td>\n",
              "      <td>1133.0</td>\n",
              "      <td>1700.0</td>\n",
              "      <td>2018.0</td>\n",
              "      <td>images/Pierre Huyghe-Sans titre double-face-1-...</td>\n",
              "      <td>1962.0</td>\n",
              "      <td>98.0</td>\n",
              "      <td>12992.24</td>\n",
              "      <td>2208.0</td>\n",
              "      <td>9.1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3.032216</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8558 rows × 107 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       creation_year  height(inch)  ...  log hammer price  binned\n",
              "1             1964.0          22.0  ...          6.060698      13\n",
              "3             1985.0          20.0  ...          4.698970       7\n",
              "4             1983.0          20.0  ...          4.845098       8\n",
              "5             1976.0           8.0  ...          4.845098       8\n",
              "6             1985.0           8.0  ...          4.857332       8\n",
              "...              ...           ...  ...               ...     ...\n",
              "14699         1999.0           2.0  ...          5.496337      10\n",
              "14700         1994.0           2.0  ...          5.685321      11\n",
              "14701         1995.0          79.0  ...          5.643453      11\n",
              "14702         1996.0          49.0  ...          4.778151       8\n",
              "14703         1986.0          39.0  ...          3.032216       1\n",
              "\n",
              "[8558 rows x 107 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zfu5j_zDs2ga",
        "colab_type": "code",
        "outputId": "734b1aa8-4635-4431-ff52-092de37561d8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "#########################\n",
        "# 2018 and beyond X / Y #\n",
        "#########################\n",
        "\n",
        "dataset = df.values\n",
        "\n",
        "# Shuffle rows to make dev vs testing split easier later \n",
        "df = df.sample(frac=1)\n",
        "\n",
        "# Train set from < 2018 data\n",
        "# Dev and Test set from >= 2018 data\n",
        "\n",
        "df_train = df[df['auction_year'] < 2018.]\n",
        "df_devtest = df[df['auction_year'] >= 2018.]\n",
        "\n",
        "print(\"df_train\",df_train.shape)\n",
        "print(\"df_devtest\",df_devtest.shape)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "df_train (7105, 107)\n",
            "df_devtest (1453, 107)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VNTqYPu3fEYc",
        "colab_type": "code",
        "outputId": "20b43e3b-729b-4955-83f3-b4d5c78c70ff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        }
      },
      "source": [
        "# Making training/testing/evaluation for image/numeric\n",
        "\n",
        "## this part for Images and Y value \n",
        "dataset_train = df_train.values\n",
        "X_image_train = dataset_train[:,6]\n",
        "Y_train = dataset_train[:,106]\n",
        "\n",
        "dataset_devtest = df_devtest.values\n",
        "X_image_devtest = dataset_devtest[:,6]\n",
        "Y_devtest = dataset_devtest[:,106]\n",
        "\n",
        "## this part for numerical data ##\n",
        "dataset_train=df_train.drop(columns=['image','log hammer price','binned'])\n",
        "dataset_devtest=df_devtest.drop(columns=['image','log hammer price','binned'])\n",
        "\n",
        "X_numeric_train = dataset_train.values\n",
        "X_numeric_devtest = dataset_devtest.values\n",
        "\n",
        "## split dev set and test set \n",
        "\n",
        "X_image_dev = X_image_devtest[:725]\n",
        "X_image_test = X_image_devtest[725:]\n",
        "Y_dev = Y_devtest[:725]\n",
        "Y_test = Y_devtest[725:]\n",
        "X_numeric_dev = X_numeric_devtest[:725]\n",
        "X_numeric_test = X_numeric_devtest[725:]\n",
        "\n",
        "## final check \n",
        "print (\"X_image_train\", X_image_train.shape)\n",
        "print (\"X_numeric_train\", X_numeric_train.shape)\n",
        "print (\"Y_train\", Y_train.shape)\n",
        "\n",
        "#print(type(X_image_tt))\n",
        "print (\"X_image_dev\", X_image_dev.shape)\n",
        "print (\"X_image_test\", X_image_test.shape)\n",
        "print (\"X_numeric_dev\", X_numeric_dev.shape)\n",
        "print (\"X_numeric_test\", X_numeric_test.shape)\n",
        "print (\"Y_dev\", Y_dev.shape)\n",
        "print (\"Y_test\", Y_test.shape)\n",
        "\n",
        "#print(type(Y_tt))\n",
        "X_numeric_test"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X_image_train (7105,)\n",
            "X_numeric_train (7105, 104)\n",
            "Y_train (7105,)\n",
            "X_image_dev (725,)\n",
            "X_image_test (728,)\n",
            "X_numeric_dev (725, 104)\n",
            "X_numeric_test (728, 104)\n",
            "Y_dev (725,)\n",
            "Y_test (728,)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[2.011e+03, 4.000e+00, 6.800e+01, ..., 0.000e+00, 0.000e+00,\n",
              "        0.000e+00],\n",
              "       [1.985e+03, 8.000e+00, 1.000e+01, ..., 0.000e+00, 0.000e+00,\n",
              "        0.000e+00],\n",
              "       [1.997e+03, 1.800e+01, 2.000e+01, ..., 0.000e+00, 1.000e+00,\n",
              "        0.000e+00],\n",
              "       ...,\n",
              "       [1.953e+03, 1.400e+01, 2.000e+01, ..., 0.000e+00, 0.000e+00,\n",
              "        0.000e+00],\n",
              "       [1.964e+03, 2.400e+01, 2.400e+01, ..., 0.000e+00, 0.000e+00,\n",
              "        0.000e+00],\n",
              "       [2.006e+03, 3.000e+01, 4.300e+01, ..., 0.000e+00, 0.000e+00,\n",
              "        0.000e+00]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3sYYHv8aw12x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Y train, dev, test set in log hammer price\n",
        "Y_train_loghammerprice=df_train['log hammer price']\n",
        "Y_devtest_loghammerprice=df_devtest['log hammer price']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y3qGDzjAxuOL",
        "colab_type": "code",
        "outputId": "a3334aa4-eedd-41ad-e8d6-078eaa7b872a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "Y_dev_loghammerprice = Y_devtest_loghammerprice[:725]\n",
        "Y_test_loghammerprice = Y_devtest_loghammerprice[725:]\n",
        "Y_train_loghammerprice"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4007     5.273200\n",
              "4114     5.903090\n",
              "808      5.079181\n",
              "5295     4.662843\n",
              "8487     5.290551\n",
              "           ...   \n",
              "3907     5.795880\n",
              "12801    5.602060\n",
              "7387     5.353224\n",
              "4939     3.204120\n",
              "14633    4.588518\n",
              "Name: log hammer price, Length: 7105, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KW71jXL5bEWR",
        "colab_type": "code",
        "outputId": "992c7785-76dc-4b0e-bc76-712409870206",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "## skip if using the whole dataset ##\n",
        "#image_number_start = 3000\n",
        "#image_number_end = 3400\n",
        "\n",
        "#load_image = X_image_train[image_number_start:image_number_end]\n",
        "#load_numeric = X_numeric_train[image_number_start:image_number_end]\n",
        "#load_bin = Y_train[image_number_start:image_number_end]\n",
        "\n",
        "#load_image_test = X_image_test[image_number_start:image_number_end]\n",
        "#load_numeric_test = X_numeric_test[image_number_start:image_number_end]\n",
        "#load_bin_test = Y_test[image_number_start:image_number_end]\n",
        "\n",
        "  ## load_image\n",
        "  #problem_image = 'images/Andy Warhol-Heaven and Hell Are Just One Breath Away (Positive and Negati                 ...-28-20.jpg' #X_image[510]\n",
        "  #print(problem_image)\n",
        "\n",
        "  # Output Images \n",
        " # print(\"test image\")\n",
        "#imgg = mpimg.imread(load_image[142]) \n",
        " # plt.imshow(imgg) \n",
        "\"\""
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "''"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NfVWeJI8vyay",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#################################\n",
        "## CNN ##########################\n",
        "#################################"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iamDkN3Kh44I",
        "colab_type": "code",
        "outputId": "a5c86a54-62ce-4b01-ed62-0b027396acf4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "################################\n",
        "## Batch pre processing block ##\n",
        "## You do it only once - #######\n",
        "################################\n",
        "\"\"\"\n",
        "import cv2\n",
        "import glob\n",
        "from PIL import Image\n",
        "from skimage.transform import resize\n",
        "from keras.preprocessing import image\n",
        "from keras.preprocessing.image import save_img\n",
        "\n",
        "filenames = [img for img in glob.glob(\"images/*.jpg\")]\n",
        "\n",
        "images = []\n",
        "\n",
        "for img in filenames:\n",
        "    print(\"images/reduced\"+img)\n",
        "    n = cv2.imread(img)\n",
        "    n2 = cv2.resize(n,(224,224))\n",
        "    status = cv2.imwrite(\"images/reduced\"+img , n2)\n",
        "    print(\"Image writtedn to file-system : \", status)\n",
        "    \n",
        "\"\"\""
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nimport cv2\\nimport glob\\nfrom PIL import Image\\nfrom skimage.transform import resize\\nfrom keras.preprocessing import image\\nfrom keras.preprocessing.image import save_img\\n\\nfilenames = [img for img in glob.glob(\"images/*.jpg\")]\\n\\nimages = []\\n\\nfor img in filenames:\\n    print(\"images/reduced\"+img)\\n    n = cv2.imread(img)\\n    n2 = cv2.resize(n,(224,224))\\n    status = cv2.imwrite(\"images/reduced\"+img , n2)\\n    print(\"Image writtedn to file-system : \", status)\\n    \\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-rG_IKBnakxV",
        "colab_type": "code",
        "outputId": "8aea5aca-500e-4a60-b329-cc2268921c3e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "\"\"\"\n",
        "# Test section\n",
        "\n",
        "#from PIL import Image\n",
        "#from skimage.transform import resize\n",
        "#from keras.preprocessing import image\n",
        "\n",
        "import cv2\n",
        "import glob\n",
        "from PIL import Image\n",
        "from skimage.transform import resize\n",
        "from keras.preprocessing import image\n",
        "from keras.preprocessing.image import save_img\n",
        "\n",
        "X_image_trainarray = []\n",
        "count = 0\n",
        "\n",
        "for f in X_image_train:\n",
        "    print(count, len(X_image_train), f)\n",
        "    m = cv2.imread(\"images/reduced\"+f)\n",
        "    m = image.img_to_array(m)\n",
        "    X_image_trainarray.append(m)\n",
        "    count += 1\n",
        "\n",
        "\n",
        "#x_Image_array = np.array(x_Image_array)\n",
        "#x_Image_array.shape\n",
        "\n",
        "\"\"\""
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n# Test section\\n\\n#from PIL import Image\\n#from skimage.transform import resize\\n#from keras.preprocessing import image\\n\\nimport cv2\\nimport glob\\nfrom PIL import Image\\nfrom skimage.transform import resize\\nfrom keras.preprocessing import image\\nfrom keras.preprocessing.image import save_img\\n\\nX_image_trainarray = []\\ncount = 0\\n\\nfor f in X_image_train:\\n    print(count, len(X_image_train), f)\\n    m = cv2.imread(\"images/reduced\"+f)\\n    m = image.img_to_array(m)\\n    X_image_trainarray.append(m)\\n    count += 1\\n\\n\\n#x_Image_array = np.array(x_Image_array)\\n#x_Image_array.shape\\n\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "arBaELy6gBNo",
        "colab_type": "code",
        "outputId": "c0268f77-8a14-44ee-af6d-4dd4bf6d70b9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "\"\"\"\n",
        "X_image_devarray = []\n",
        "count = 0\n",
        "\n",
        "for f in X_image_dev:\n",
        "    print(count, len(X_image_dev), f)\n",
        "    m = cv2.imread(\"images/reduced\"+f)\n",
        "    m = image.img_to_array(m)\n",
        "    X_image_devarray.append(m)\n",
        "    count += 1\n",
        "\"\"\""
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nX_image_devarray = []\\ncount = 0\\n\\nfor f in X_image_dev:\\n    print(count, len(X_image_dev), f)\\n    m = cv2.imread(\"images/reduced\"+f)\\n    m = image.img_to_array(m)\\n    X_image_devarray.append(m)\\n    count += 1\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NskhVBNMgA8j",
        "colab_type": "code",
        "outputId": "24c713c0-82d6-4562-c68a-4cca725bc9db",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "\"\"\"\n",
        "X_image_testarray = []\n",
        "count = 0\n",
        "\n",
        "for f in X_image_test:\n",
        "    print(count, len(X_image_test), f)\n",
        "    m = cv2.imread(\"images/reduced\"+f)\n",
        "    m = image.img_to_array(m)\n",
        "    X_image_testarray.append(m)\n",
        "    count += 1\n",
        "\n",
        "\"\"\""
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nX_image_testarray = []\\ncount = 0\\n\\nfor f in X_image_test:\\n    print(count, len(X_image_test), f)\\n    m = cv2.imread(\"images/reduced\"+f)\\n    m = image.img_to_array(m)\\n    X_image_testarray.append(m)\\n    count += 1\\n\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cwmZbSbyz09e",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "99d364df-8cbe-4d1e-e7c9-8b352cad921d"
      },
      "source": [
        "\"\"\"\n",
        "# convert to array\n",
        "X_image_trainarray = np.asarray(X_image_trainarray)\n",
        "X_image_devarray = np.asarray(X_image_devarray)\n",
        "X_image_testarray = np.asarray(X_image_testarray)\n",
        "\n",
        "# save as .npy files\n",
        "np.save('X_image_trainarray.npy', X_image_trainarray)\n",
        "np.save('X_image_devarray.npy', X_image_devarray)\n",
        "np.save('X_image_testarray.npy', X_image_testarray)\n",
        "\n",
        "np.save('X_numeric_test.npy', X_numeric_test)\n",
        "np.save('X_numeric_train.npy', X_numeric_train)\n",
        "np.save('X_numeric_dev.npy', X_numeric_dev)\n",
        "\n",
        "np.save('Y_train_loghammerprice.npy', Y_train_loghammerprice)\n",
        "np.save('Y_dev_loghammerprice.npy', Y_dev_loghammerprice)\n",
        "np.save('Y_test_loghammerprice.npy', Y_test_loghammerprice)\n",
        "\"\"\""
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\n# convert to array\\nX_image_trainarray = np.asarray(X_image_trainarray)\\nX_image_devarray = np.asarray(X_image_devarray)\\nX_image_testarray = np.asarray(X_image_testarray)\\n\\n# save as .npy files\\nnp.save('X_image_trainarray.npy', X_image_trainarray)\\nnp.save('X_image_devarray.npy', X_image_devarray)\\nnp.save('X_image_testarray.npy', X_image_testarray)\\n\\nnp.save('X_numeric_test.npy', X_numeric_test)\\nnp.save('X_numeric_train.npy', X_numeric_train)\\nnp.save('X_numeric_dev.npy', X_numeric_dev)\\n\\nnp.save('Y_train_loghammerprice.npy', Y_train_loghammerprice)\\nnp.save('Y_dev_loghammerprice.npy', Y_dev_loghammerprice)\\nnp.save('Y_test_loghammerprice.npy', Y_test_loghammerprice)\\n\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2A3QZoudRUaH",
        "colab_type": "code",
        "outputId": "c6150be3-49e2-4679-c301-ac02773e6ecc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "\"\"\"\n",
        "print(\"X_image_trainarray\", X_image_trainarray.shape)\n",
        "print(\"X_image_devarray\", X_image_devarray.shape)\n",
        "print(\"X_image_testarray\", X_image_testarray.shape)\n",
        "print(\"X_numeric_test\", X_numeric_test.shape)\n",
        "print(\"X_numeric_train\", X_numeric_train.shape)\n",
        "print(\"X_numeric_dev\", X_numeric_dev.shape)\n",
        "print(\"Y_train_loghammerprice\", Y_train_loghammerprice.shape)\n",
        "print(\"Y_dev_loghammerprice\", Y_dev_loghammerprice.shape)\n",
        "print(\"Y_test_loghammerprice\", Y_test_loghammerprice.shape)\n",
        "\"\"\""
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nprint(\"X_image_trainarray\", X_image_trainarray.shape)\\nprint(\"X_image_devarray\", X_image_devarray.shape)\\nprint(\"X_image_testarray\", X_image_testarray.shape)\\nprint(\"X_numeric_test\", X_numeric_test.shape)\\nprint(\"X_numeric_train\", X_numeric_train.shape)\\nprint(\"X_numeric_dev\", X_numeric_dev.shape)\\nprint(\"Y_train_loghammerprice\", Y_train_loghammerprice.shape)\\nprint(\"Y_dev_loghammerprice\", Y_dev_loghammerprice.shape)\\nprint(\"Y_test_loghammerprice\", Y_test_loghammerprice.shape)\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E-HphSPUeapP",
        "colab_type": "code",
        "outputId": "b7635fa5-bc28-4b8b-a228-f9901f8b6b92",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "# one-hot encode the log hammer price <==== NEED TO BE FIXED!!!!\n",
        "encoder = LabelEncoder()\n",
        "\n",
        "encoder.fit(Y_train)\n",
        "encoded_Y_train = encoder.transform(Y_train)\n",
        "dummy_Y_train = np_utils.to_categorical(encoded_Y_train) \n",
        "\n",
        "encoder.fit(Y_dev)\n",
        "encoded_Y_dev = encoder.transform(Y_dev)\n",
        "dummy_Y_dev = np_utils.to_categorical(encoded_Y_dev) \n",
        "\n",
        "encoder.fit(Y_test)\n",
        "encoded_Y_test = encoder.transform(Y_test)\n",
        "dummy_Y_test = np_utils.to_categorical(encoded_Y_test) \n",
        "\n",
        "print(dummy_Y_train)\n",
        "print(dummy_Y_train.shape)\n",
        "print(dummy_Y_dev.shape)\n",
        "print(dummy_Y_test.shape)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " ...\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 1. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]]\n",
            "(7105, 21)\n",
            "(725, 19)\n",
            "(728, 21)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tL4_Tpd6Ozkm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# load dataset from files\n",
        "\n",
        "X_image_trainarray = np.load('X_image_trainarray.npy')\n",
        "X_image_devarray = np.load('X_image_devarray.npy')\n",
        "X_image_testarray = np.load('X_image_testarray.npy')\n",
        "X_numeric_train = np.load('X_numeric_train.npy')\n",
        "X_numeric_dev = np.load('X_numeric_dev.npy')\n",
        "X_numeric_test = np.load('X_numeric_test.npy')\n",
        "Y_train_loghammerprice = np.load('Y_train_loghammerprice.npy')\n",
        "Y_dev_loghammerprice = np.load('Y_dev_loghammerprice.npy')\n",
        "Y_test_loghammerprice = np.load('Y_test_loghammerprice.npy')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vBcvJ28ARLYx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Subsample the total sample space to accelerate Image CNN TensorBoard search. ##\n",
        "\n",
        "subsample_factor=10\n",
        "X_train_sub = np.floor(len(X_image_trainarray)/subsample_factor)\n",
        "X_dev_sub = np.floor(len(X_image_devarray)/subsample_factor)\n",
        "X_test_sub = np.floor(len(X_image_testarray)/subsample_factor)\n",
        "\n",
        "# This is actual number of entries after sub-sampling \n",
        "X_train_sub = X_train_sub.astype(int)\n",
        "X_dev_sub = X_dev_sub.astype(int)\n",
        "X_test_sub = X_test_sub.astype(int)\n",
        "\n",
        "# This gets the indices to make sure the same entries are subsampled between X and Y \n",
        "X_train_sub_idx = np.random.choice(np.arange(len(X_image_trainarray)), X_train_sub, replace=False)\n",
        "X_dev_sub_idx = np.random.choice(np.arange(len(X_image_devarray)), X_dev_sub, replace=False)\n",
        "X_test_sub_idx = np.random.choice(np.arange(len(X_image_testarray)), X_test_sub, replace=False)\n",
        "\n",
        "# Apply the indices \n",
        "X_image_trainarray_sub = X_image_trainarray[X_train_sub_idx,:,:,:]\n",
        "X_image_devarray_sub = X_image_devarray[X_dev_sub_idx,:,:,:]\n",
        "X_image_testarray_sub = X_image_testarray[X_test_sub_idx,:,:,:]\n",
        "Y_train_loghammerprice_sub = Y_train_loghammerprice[X_train_sub_idx]\n",
        "Y_dev_loghammerprice_sub = Y_dev_loghammerprice[X_dev_sub_idx]\n",
        "Y_test_loghammerprice_sub = Y_test_loghammerprice[X_test_sub_idx]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ciDDKeELfzE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "outputId": "48a2f46b-6d3d-4fc6-c97b-a5fa62455b61"
      },
      "source": [
        "print(\"X_image_trainarray\", X_image_trainarray.shape)\n",
        "print(\"X_image_devarray\", X_image_devarray.shape)\n",
        "print(\"X_image_testarray\", X_image_testarray.shape)\n",
        "\n",
        "print(\"X_image_trainarray_sub\", X_image_trainarray_sub.shape)\n",
        "print(\"X_image_devarray_sub\", X_image_devarray_sub.shape)\n",
        "print(\"X_image_testarray_sub\", X_image_testarray_sub.shape)\n",
        "\n",
        "print(\"X_numeric_train\", X_numeric_train.shape)\n",
        "print(\"X_numeric_test\", X_numeric_test.shape)\n",
        "print(\"X_numeric_dev\", X_numeric_dev.shape)\n",
        "\n",
        "print(\"Y_train_loghammerprice\", Y_train_loghammerprice.shape)\n",
        "print(\"Y_dev_loghammerprice\", Y_dev_loghammerprice.shape)\n",
        "print(\"Y_test_loghammerprice\", Y_test_loghammerprice.shape)\n",
        "\n",
        "print(\"Y_train_loghammerprice_sub\", Y_train_loghammerprice_sub.shape)\n",
        "print(\"Y_dev_loghammerprice_sub\", Y_dev_loghammerprice_sub.shape)\n",
        "print(\"Y_test_loghammerprice_sub\", Y_test_loghammerprice_sub.shape)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X_image_trainarray (7105, 224, 224, 3)\n",
            "X_image_devarray (725, 224, 224, 3)\n",
            "X_image_testarray (728, 224, 224, 3)\n",
            "X_image_trainarray_sub (710, 224, 224, 3)\n",
            "X_image_devarray_sub (72, 224, 224, 3)\n",
            "X_image_testarray_sub (72, 224, 224, 3)\n",
            "X_numeric_train (7105, 104)\n",
            "X_numeric_test (728, 104)\n",
            "X_numeric_dev (725, 104)\n",
            "Y_train_loghammerprice (7105,)\n",
            "Y_dev_loghammerprice (725,)\n",
            "Y_test_loghammerprice (728,)\n",
            "Y_train_loghammerprice_sub (710,)\n",
            "Y_dev_loghammerprice_sub (72,)\n",
            "Y_test_loghammerprice_sub (72,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5qr5Wm7t2upa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#standardize image arrays\n",
        "X_image_trainarray_sub /=255\n",
        "X_image_devarray_sub /=255\n",
        "X_image_testarray_sub /=255"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WK3u2RGnQN_8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "dfb4209d-0e4d-48ef-c110-b37aff79d6b8"
      },
      "source": [
        "\"\"\"\n",
        "# Split X_numeric into numerical and categorical data. \n",
        "X_numeric_train_1 = X_numeric_train[:,:11]\n",
        "X_numeric_train_2 = X_numeric_train[:,11:]\n",
        "\n",
        "X_numeric_dev_1 = X_numeric_dev[:,:11]\n",
        "X_numeric_dev_2 = X_numeric_dev[:,11:]\n",
        "\n",
        "X_numeric_test_1 = X_numeric_test[:,:11]\n",
        "X_numeric_test_2 = X_numeric_test[:,11:]\n",
        "\n",
        "#standardize numerical data using mean and standard deviation of training samples\n",
        "scaler = StandardScaler()\n",
        "\n",
        "scaler.fit(X_numeric_train_1)\n",
        "X_numeric_train_1_scaled = scaler.transform(X_numeric_train_1)\n",
        "X_numeric_dev_1_scaled = scaler.transform(X_numeric_dev_1)\n",
        "X_numeric_test_1_scaled = scaler.transform(X_numeric_test_1)\n",
        "\n",
        "# construct our train/dev/test set by concatenating the categorical features with the continuous features\n",
        "X_numeric_train_scaled = np.hstack([X_numeric_train_1_scaled, X_numeric_train_2])\n",
        "X_numeric_dev_scaled = np.hstack([X_numeric_dev_1_scaled, X_numeric_dev_2])\n",
        "X_numeric_test_scaled = np.hstack([X_numeric_test_1_scaled, X_numeric_test_2])\n",
        "\"\"\""
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n# Split X_numeric into numerical and categorical data. \\nX_numeric_train_1 = X_numeric_train[:,:11]\\nX_numeric_train_2 = X_numeric_train[:,11:]\\n\\nX_numeric_dev_1 = X_numeric_dev[:,:11]\\nX_numeric_dev_2 = X_numeric_dev[:,11:]\\n\\nX_numeric_test_1 = X_numeric_test[:,:11]\\nX_numeric_test_2 = X_numeric_test[:,11:]\\n\\n#standardize numerical data using mean and standard deviation of training samples\\nscaler = StandardScaler()\\n\\nscaler.fit(X_numeric_train_1)\\nX_numeric_train_1_scaled = scaler.transform(X_numeric_train_1)\\nX_numeric_dev_1_scaled = scaler.transform(X_numeric_dev_1)\\nX_numeric_test_1_scaled = scaler.transform(X_numeric_test_1)\\n\\n# construct our train/dev/test set by concatenating the categorical features with the continuous features\\nX_numeric_train_scaled = np.hstack([X_numeric_train_1_scaled, X_numeric_train_2])\\nX_numeric_dev_scaled = np.hstack([X_numeric_dev_1_scaled, X_numeric_dev_2])\\nX_numeric_test_scaled = np.hstack([X_numeric_test_1_scaled, X_numeric_test_2])\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qS64K4pFL7lB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "load_ext tensorboard"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_KMzdqh5L7rk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!rm -rf ./logs/ "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5VZ1uKxhL7xz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from time import time\n",
        "from datetime import datetime\n",
        "from packaging import version\n",
        "import tensorflow as tf\n",
        "from keras import optimizers\n",
        "\n",
        "from keras.callbacks import TensorBoard\n",
        "from tensorboard.plugins.hparams import api as hp\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y0hWQoCGL712",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "HP_NUM_UNITS = hp.HParam('num_units', hp.Discrete([32, 64, 128]))\n",
        "HP_BATCHN = hp.HParam('batch_number', hp.Discrete([32, 64]))\n",
        "HP_LL = hp.HParam('learning_rate', hp.Discrete([0.001, 0.002, 0.004]))\n",
        "HP_DROPOUT = hp.HParam('dropout', hp.Discrete([0.2]))\n",
        "HP_KERNEL = hp.HParam('kernel_size', hp.Discrete([5]))\n",
        "HP_OPTIMIZER = hp.HParam('optimizer', hp.Discrete(['adam']))\n",
        "\n",
        "\n",
        "\n",
        "METRIC_ACCURACY = 'accuracy'\n",
        "\n",
        "#with tf.summary.FileWriter('logs/hparam_tuning'):\n",
        "with tf.summary.create_file_writer('logs/hparam_tuning').as_default():\n",
        "  hp.hparams_config(\n",
        "    hparams=[HP_NUM_UNITS, HP_DROPOUT, HP_KERNEL, HP_OPTIMIZER, HP_LL, HP_BATCHN],\n",
        "    metrics=[hp.Metric(METRIC_ACCURACY, display_name='Accuracy')],\n",
        "  )\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JvVGcMgZ1LFh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "log_dir=\"logs/fit/\"+ datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "\n",
        "### When training Keras models, you can use callbacks instead of writing these directly:\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir.format(time()))\n",
        "#hp_callback = hp.KerasCallback(log_dir, hparams)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GEHWssMeQ0n_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# root mean squared error (rmse) for regression\n",
        "def rmse(y_true, y_pred):\n",
        "    from keras import backend\n",
        "    return backend.sqrt(backend.mean(backend.square(y_pred - y_true), axis=-1))\n",
        "\n",
        "# mean squared error (mse) for regression\n",
        "def mse(y_true, y_pred):\n",
        "    from keras import backend\n",
        "    return backend.mean(backend.square(y_pred - y_true), axis=-1)\n",
        "\n",
        "# coefficient of determination (R^2) for regression\n",
        "def r_square(y_true, y_pred):\n",
        "    from keras import backend as K\n",
        "    SS_res =  K.sum(K.square(y_true - y_pred)) \n",
        "    SS_tot = K.sum(K.square(y_true - K.mean(y_true))) \n",
        "    return (1 - SS_res/(SS_tot + K.epsilon()))\n",
        "\n",
        "def r_square_loss(y_true, y_pred):\n",
        "    from keras import backend as K\n",
        "    SS_res =  K.sum(K.square(y_true - y_pred)) \n",
        "    SS_tot = K.sum(K.square(y_true - K.mean(y_true))) \n",
        "    return 1 - ( 1 - SS_res/(SS_tot + K.epsilon()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v_NzTZFDL75g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "from keras import optimizers\n",
        "\n",
        "def train_test_model(hparams):\n",
        "  input_shape = (224,224,3)\n",
        "  pool_size = 3\n",
        "#  final_node_size = dummy_load_bin.shape[1]\n",
        "\n",
        "  model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Conv2D(hparams[HP_NUM_UNITS], (hparams[HP_KERNEL], hparams[HP_KERNEL]), activation='relu', padding='same', input_shape=input_shape),\n",
        "    tf.keras.layers.BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001, center=True, scale=True, beta_initializer='zeros', gamma_initializer='ones', moving_mean_initializer='zeros', moving_variance_initializer='ones'),\n",
        "    tf.keras.layers.MaxPooling2D((pool_size, pool_size), strides=(2, 2), padding='same'),\n",
        "    tf.keras.layers.Dropout(hparams[HP_DROPOUT]),\n",
        "\n",
        "    tf.keras.layers.Conv2D(hparams[HP_NUM_UNITS], (hparams[HP_KERNEL], hparams[HP_KERNEL]), activation='relu', padding='same', input_shape=input_shape),\n",
        "    tf.keras.layers.BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001, center=True, scale=True, beta_initializer='zeros', gamma_initializer='ones', moving_mean_initializer='zeros', moving_variance_initializer='ones'),\n",
        "    tf.keras.layers.MaxPooling2D((pool_size, pool_size), strides=(2, 2), padding='same'),\n",
        "    tf.keras.layers.Dropout(hparams[HP_DROPOUT]),\n",
        "\n",
        "    tf.keras.layers.Conv2D(hparams[HP_NUM_UNITS], (hparams[HP_KERNEL], hparams[HP_KERNEL]), activation='relu', padding='same', input_shape=input_shape),\n",
        "    tf.keras.layers.BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001, center=True, scale=True, beta_initializer='zeros', gamma_initializer='ones', moving_mean_initializer='zeros', moving_variance_initializer='ones'),\n",
        "    tf.keras.layers.MaxPooling2D((pool_size, pool_size), strides=(2, 2), padding='same'),\n",
        "    tf.keras.layers.Dropout(hparams[HP_DROPOUT]),\n",
        "\n",
        "    tf.keras.layers.Conv2D(hparams[HP_NUM_UNITS], (hparams[HP_KERNEL], hparams[HP_KERNEL]), activation='relu', padding='same', input_shape=input_shape),\n",
        "    tf.keras.layers.BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001, center=True, scale=True, beta_initializer='zeros', gamma_initializer='ones', moving_mean_initializer='zeros', moving_variance_initializer='ones'),\n",
        "    tf.keras.layers.MaxPooling2D((pool_size, pool_size), strides=(2, 2), padding='same'),\n",
        "    tf.keras.layers.Dropout(hparams[HP_DROPOUT]),\n",
        "\n",
        "    tf.keras.layers.Conv2D(hparams[HP_NUM_UNITS], (hparams[HP_KERNEL], hparams[HP_KERNEL]), activation='relu', padding='same', input_shape=input_shape),\n",
        "    tf.keras.layers.BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001, center=True, scale=True, beta_initializer='zeros', gamma_initializer='ones', moving_mean_initializer='zeros', moving_variance_initializer='ones'),\n",
        "    tf.keras.layers.MaxPooling2D((pool_size, pool_size), strides=(2, 2), padding='same'),\n",
        "    tf.keras.layers.Dropout(hparams[HP_DROPOUT]),\n",
        "\n",
        "    tf.keras.layers.Conv2D(hparams[HP_NUM_UNITS], (hparams[HP_KERNEL], hparams[HP_KERNEL]), activation='relu', padding='same', input_shape=input_shape),\n",
        "    tf.keras.layers.BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001, center=True, scale=True, beta_initializer='zeros', gamma_initializer='ones', moving_mean_initializer='zeros', moving_variance_initializer='ones'),\n",
        "    tf.keras.layers.MaxPooling2D((pool_size, pool_size), strides=(2, 2), padding='same'),\n",
        "    tf.keras.layers.Dropout(hparams[HP_DROPOUT]),\n",
        "\n",
        "    tf.keras.layers.Conv2D(hparams[HP_NUM_UNITS], (hparams[HP_KERNEL], hparams[HP_KERNEL]), activation='relu', padding='same', input_shape=input_shape),\n",
        "    tf.keras.layers.BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001, center=True, scale=True, beta_initializer='zeros', gamma_initializer='ones', moving_mean_initializer='zeros', moving_variance_initializer='ones'),\n",
        "    tf.keras.layers.MaxPooling2D((pool_size, pool_size), strides=(2, 2), padding='same'),\n",
        "    tf.keras.layers.Dropout(hparams[HP_DROPOUT]),\n",
        "    \n",
        "    tf.keras.layers.Conv2D(hparams[HP_NUM_UNITS], (hparams[HP_KERNEL], hparams[HP_KERNEL]), activation='relu', padding='same', input_shape=input_shape),\n",
        "    tf.keras.layers.BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001, center=True, scale=True, beta_initializer='zeros', gamma_initializer='ones', moving_mean_initializer='zeros', moving_variance_initializer='ones'),\n",
        "    tf.keras.layers.MaxPooling2D((pool_size, pool_size), strides=(2, 2), padding='same'),\n",
        "    tf.keras.layers.Dropout(hparams[HP_DROPOUT]),\n",
        "\n",
        "    tf.keras.layers.Conv2D(hparams[HP_NUM_UNITS], (hparams[HP_KERNEL], hparams[HP_KERNEL]), activation='relu', padding='same', input_shape=input_shape),\n",
        "    tf.keras.layers.BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001, center=True, scale=True, beta_initializer='zeros', gamma_initializer='ones', moving_mean_initializer='zeros', moving_variance_initializer='ones'),\n",
        "    tf.keras.layers.MaxPooling2D((pool_size, pool_size), strides=(2, 2), padding='same'),\n",
        "    tf.keras.layers.Dropout(hparams[HP_DROPOUT]),\n",
        "\n",
        "    tf.keras.layers.Conv2D(hparams[HP_NUM_UNITS], (hparams[HP_KERNEL], hparams[HP_KERNEL]), activation='relu', padding='same', input_shape=input_shape),\n",
        "    tf.keras.layers.BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001, center=True, scale=True, beta_initializer='zeros', gamma_initializer='ones', moving_mean_initializer='zeros', moving_variance_initializer='ones'),\n",
        "    tf.keras.layers.MaxPooling2D((pool_size, pool_size), strides=(2, 2), padding='same'),\n",
        "    tf.keras.layers.Dropout(hparams[HP_DROPOUT]),\n",
        "\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(1, activation=tf.nn.relu),\n",
        "  ])\n",
        "  \n",
        "    \n",
        "  #sgd = optimizers.SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
        "  model.compile(\n",
        "      learning_rate = hparams[HP_LL],\n",
        "      optimizer = hparams[HP_OPTIMIZER],\n",
        "      loss=rmse, \n",
        "      metrics=[r_square],\n",
        "      )\n",
        "  \n",
        "  #callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)\n",
        "\n",
        "  model.fit(\n",
        "      X_image_trainarray_sub, \n",
        "      Y_train_loghammerprice_sub, \n",
        "      batch_size=hparams[HP_BATCHN], \n",
        "      epochs=20, \n",
        "      callbacks=[tensorboard_callback], \n",
        "      validation_data = (X_image_devarray_sub, Y_dev_loghammerprice_sub)) \n",
        "  \n",
        "  _, result = model.evaluate(X_image_testarray_sub, Y_test_loghammerprice_sub) \n",
        "  \n",
        "  return result\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TYAKyjeAL7vL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def run(run_dir, hparams):\n",
        "  with tf.summary.create_file_writer(run_dir).as_default():\n",
        "    hp.hparams(hparams)  # record the values used in this trial\n",
        "    accuracy = train_test_model(hparams)\n",
        "    print(\"accuracy\", accuracy)\n",
        "    tf.summary.scalar(METRIC_ACCURACY, accuracy, step=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MYNoPXeeL7pO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "18ceb386-aad9-4975-bd44-66b5f98793a7"
      },
      "source": [
        "session_num = 0\n",
        "\n",
        "for num_units in HP_NUM_UNITS.domain.values:\n",
        "  for dropout_rate in HP_DROPOUT.domain.values:\n",
        "    for kernel_size in HP_KERNEL.domain.values:\n",
        "      for optimizer in HP_OPTIMIZER.domain.values:\n",
        "        for learning_rate in HP_LL.domain.values:\n",
        "          for batch_number in HP_BATCHN.domain.values:\n",
        "            hparams = {\n",
        "                HP_NUM_UNITS: num_units,\n",
        "                HP_DROPOUT: dropout_rate,\n",
        "                HP_KERNEL: kernel_size,\n",
        "                HP_OPTIMIZER: optimizer,\n",
        "                HP_LL: learning_rate,\n",
        "                HP_BATCHN: batch_number,\n",
        "            }\n",
        "            run_name = \"run-%d\" % session_num\n",
        "            print('--- Starting trial: %s' % run_name)\n",
        "            print({h.name: hparams[h] for h in hparams})\n",
        "            run('logs/hparam_tuning/' + run_name, hparams)\n",
        "            session_num += 1"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--- Starting trial: run-0\n",
            "{'num_units': 32, 'dropout': 0.2, 'kernel_size': 5, 'optimizer': 'adam', 'learning_rate': 0.001, 'batch_number': 32}\n",
            "Train on 710 samples, validate on 72 samples\n",
            "Epoch 1/20\n",
            "710/710 [==============================] - 85s 120ms/sample - loss: 4.1681 - r_square: -29.5849 - val_loss: 4.9008 - val_r_square: -58.3267\n",
            "Epoch 2/20\n",
            "710/710 [==============================] - 80s 113ms/sample - loss: 3.3662 - r_square: -21.6321 - val_loss: 4.8063 - val_r_square: -56.4505\n",
            "Epoch 3/20\n",
            "710/710 [==============================] - 80s 113ms/sample - loss: 2.8807 - r_square: -17.8584 - val_loss: 5.0336 - val_r_square: -61.4993\n",
            "Epoch 4/20\n",
            "710/710 [==============================] - 80s 113ms/sample - loss: 2.5275 - r_square: -14.8893 - val_loss: 5.0307 - val_r_square: -61.4612\n",
            "Epoch 5/20\n",
            "710/710 [==============================] - 80s 112ms/sample - loss: 2.3594 - r_square: -13.3914 - val_loss: 4.3716 - val_r_square: -49.9168\n",
            "Epoch 6/20\n",
            "710/710 [==============================] - 78s 110ms/sample - loss: 2.2014 - r_square: -12.6125 - val_loss: 2.3637 - val_r_square: -13.6231\n",
            "Epoch 7/20\n",
            "710/710 [==============================] - 78s 109ms/sample - loss: 2.1591 - r_square: -12.3678 - val_loss: 1.9865 - val_r_square: -9.5921\n",
            "Epoch 8/20\n",
            "710/710 [==============================] - 78s 110ms/sample - loss: 2.0657 - r_square: -10.9607 - val_loss: 2.4530 - val_r_square: -22.4557\n",
            "Epoch 9/20\n",
            "710/710 [==============================] - 77s 109ms/sample - loss: 1.9553 - r_square: -9.8305 - val_loss: 2.1405 - val_r_square: -19.9722\n",
            "Epoch 10/20\n",
            "710/710 [==============================] - 77s 108ms/sample - loss: 1.8588 - r_square: -9.9610 - val_loss: 1.0150 - val_r_square: -2.1560\n",
            "Epoch 11/20\n",
            "710/710 [==============================] - 77s 109ms/sample - loss: 1.7416 - r_square: -7.5538 - val_loss: 0.8113 - val_r_square: -1.1181\n",
            "Epoch 12/20\n",
            "710/710 [==============================] - 76s 108ms/sample - loss: 1.7081 - r_square: -8.3247 - val_loss: 3.0530 - val_r_square: -36.0076\n",
            "Epoch 13/20\n",
            "710/710 [==============================] - 75s 106ms/sample - loss: 1.6142 - r_square: -7.3481 - val_loss: 0.7877 - val_r_square: -1.8830\n",
            "Epoch 14/20\n",
            "710/710 [==============================] - 75s 106ms/sample - loss: 1.5192 - r_square: -6.0183 - val_loss: 0.7796 - val_r_square: -1.8457\n",
            "Epoch 15/20\n",
            "710/710 [==============================] - 75s 105ms/sample - loss: 1.4391 - r_square: -5.8961 - val_loss: 0.7181 - val_r_square: -1.0754\n",
            "Epoch 16/20\n",
            "710/710 [==============================] - 76s 106ms/sample - loss: 1.4362 - r_square: -5.2228 - val_loss: 0.5810 - val_r_square: -0.0815\n",
            "Epoch 17/20\n",
            "710/710 [==============================] - 76s 107ms/sample - loss: 1.3479 - r_square: -4.6893 - val_loss: 0.7888 - val_r_square: -1.5288\n",
            "Epoch 18/20\n",
            "710/710 [==============================] - 75s 106ms/sample - loss: 1.2688 - r_square: -4.1506 - val_loss: 1.0670 - val_r_square: -7.6829\n",
            "Epoch 19/20\n",
            "710/710 [==============================] - 77s 108ms/sample - loss: 1.2949 - r_square: -4.6284 - val_loss: 1.6477 - val_r_square: -12.4431\n",
            "Epoch 20/20\n",
            "710/710 [==============================] - 76s 107ms/sample - loss: 1.2885 - r_square: -4.2926 - val_loss: 0.9445 - val_r_square: -2.9426\n",
            "72/1 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 2s 23ms/sample - loss: 0.7633 - r_square: -2.9152\n",
            "accuracy -2.9151657\n",
            "--- Starting trial: run-1\n",
            "{'num_units': 32, 'dropout': 0.2, 'kernel_size': 5, 'optimizer': 'adam', 'learning_rate': 0.001, 'batch_number': 64}\n",
            "Train on 710 samples, validate on 72 samples\n",
            "Epoch 1/20\n",
            "710/710 [==============================] - 78s 110ms/sample - loss: 4.0946 - r_square: -30.0151 - val_loss: 4.8818 - val_r_square: -60.9526\n",
            "Epoch 2/20\n",
            "710/710 [==============================] - 75s 106ms/sample - loss: 3.0547 - r_square: -18.3317 - val_loss: 4.6823 - val_r_square: -56.1037\n",
            "Epoch 3/20\n",
            "710/710 [==============================] - 75s 105ms/sample - loss: 2.5451 - r_square: -14.2401 - val_loss: 4.4629 - val_r_square: -51.0033\n",
            "Epoch 4/20\n",
            "710/710 [==============================] - 75s 106ms/sample - loss: 2.2685 - r_square: -12.3051 - val_loss: 4.1751 - val_r_square: -44.6681\n",
            "Epoch 5/20\n",
            "710/710 [==============================] - 75s 106ms/sample - loss: 2.1593 - r_square: -11.2285 - val_loss: 3.9388 - val_r_square: -39.9319\n",
            "Epoch 6/20\n",
            "710/710 [==============================] - 74s 105ms/sample - loss: 2.0410 - r_square: -12.1360 - val_loss: 3.9843 - val_r_square: -40.9631\n",
            "Epoch 7/20\n",
            "710/710 [==============================] - 75s 106ms/sample - loss: 2.1322 - r_square: -10.4671 - val_loss: 5.0336 - val_r_square: -64.8077\n",
            "Epoch 8/20\n",
            "710/710 [==============================] - 74s 105ms/sample - loss: 1.9653 - r_square: -9.8493 - val_loss: 5.0336 - val_r_square: -64.8077\n",
            "Epoch 9/20\n",
            "710/710 [==============================] - 74s 105ms/sample - loss: 1.8609 - r_square: -11.3983 - val_loss: 5.0336 - val_r_square: -64.8077\n",
            "Epoch 10/20\n",
            "710/710 [==============================] - 75s 105ms/sample - loss: 1.8255 - r_square: -8.3522 - val_loss: 5.0297 - val_r_square: -64.7716\n",
            "Epoch 11/20\n",
            "710/710 [==============================] - 74s 105ms/sample - loss: 1.9124 - r_square: -14.5928 - val_loss: 4.3114 - val_r_square: -54.9414\n",
            "Epoch 12/20\n",
            "710/710 [==============================] - 75s 106ms/sample - loss: 1.7860 - r_square: -8.4424 - val_loss: 4.4099 - val_r_square: -57.3079\n",
            "Epoch 13/20\n",
            "710/710 [==============================] - 75s 106ms/sample - loss: 1.6561 - r_square: -7.6252 - val_loss: 3.7968 - val_r_square: -47.6041\n",
            "Epoch 14/20\n",
            "710/710 [==============================] - 74s 105ms/sample - loss: 1.6946 - r_square: -9.0595 - val_loss: 4.4459 - val_r_square: -53.0430\n",
            "Epoch 15/20\n",
            "710/710 [==============================] - 74s 104ms/sample - loss: 1.6457 - r_square: -7.4026 - val_loss: 3.2336 - val_r_square: -30.1437\n",
            "Epoch 16/20\n",
            "710/710 [==============================] - 74s 104ms/sample - loss: 1.6098 - r_square: -7.7810 - val_loss: 2.4935 - val_r_square: -21.2645\n",
            "Epoch 17/20\n",
            "710/710 [==============================] - 74s 105ms/sample - loss: 1.5566 - r_square: -7.0887 - val_loss: 1.3346 - val_r_square: -4.4452\n",
            "Epoch 18/20\n",
            "710/710 [==============================] - 75s 105ms/sample - loss: 1.6992 - r_square: -9.0070 - val_loss: 1.0311 - val_r_square: -2.6137\n",
            "Epoch 19/20\n",
            "710/710 [==============================] - 74s 104ms/sample - loss: 1.6242 - r_square: -6.2023 - val_loss: 1.0746 - val_r_square: -2.6081\n",
            "Epoch 20/20\n",
            "710/710 [==============================] - 74s 104ms/sample - loss: 1.5366 - r_square: -6.3286 - val_loss: 0.8527 - val_r_square: -1.4767\n",
            "72/1 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 2s 23ms/sample - loss: 0.9251 - r_square: -1.6443\n",
            "accuracy -1.6442556\n",
            "--- Starting trial: run-2\n",
            "{'num_units': 32, 'dropout': 0.2, 'kernel_size': 5, 'optimizer': 'adam', 'learning_rate': 0.002, 'batch_number': 32}\n",
            "Train on 710 samples, validate on 72 samples\n",
            "Epoch 1/20\n",
            "710/710 [==============================] - 78s 109ms/sample - loss: 3.9590 - r_square: -30.5307 - val_loss: 4.9925 - val_r_square: -60.5602\n",
            "Epoch 2/20\n",
            "710/710 [==============================] - 75s 106ms/sample - loss: 2.9030 - r_square: -18.9909 - val_loss: 4.9899 - val_r_square: -60.1539\n",
            "Epoch 3/20\n",
            "710/710 [==============================] - 75s 106ms/sample - loss: 2.4806 - r_square: -14.2417 - val_loss: 4.6870 - val_r_square: -54.5911\n",
            "Epoch 4/20\n",
            "710/710 [==============================] - 76s 107ms/sample - loss: 2.4470 - r_square: -13.9958 - val_loss: 3.7833 - val_r_square: -34.4166\n",
            "Epoch 5/20\n",
            "710/710 [==============================] - 76s 107ms/sample - loss: 2.2659 - r_square: -13.7228 - val_loss: 3.7609 - val_r_square: -35.9197\n",
            "Epoch 6/20\n",
            "710/710 [==============================] - 75s 106ms/sample - loss: 2.1852 - r_square: -12.1808 - val_loss: 3.2433 - val_r_square: -27.0377\n",
            "Epoch 7/20\n",
            "710/710 [==============================] - 75s 106ms/sample - loss: 2.1012 - r_square: -12.0453 - val_loss: 3.1524 - val_r_square: -27.7594\n",
            "Epoch 8/20\n",
            "160/710 [=====>........................] - ETA: 56s - loss: 1.9603 - r_square: -10.4846"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qaq3hmuGMOEd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "79edbe75-4285-4ba2-9fe9-cb96d5c1ba16"
      },
      "source": [
        "%tensorboard --logdir logs/fit"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "UsageError: Line magic function `%tensorboard` not found.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2sMyIyXK7pYA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%tensorboard --logdir logs/hparam_tuning/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mEQIlws2MOLN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "up to here. "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kpa6DdCvTCeP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### Text NET ##########\n",
        "\"\"\"\n",
        "from keras.layers import BatchNormalization\n",
        "from keras import regularizers\n",
        "\n",
        "def numerical_model(dim, regress=False):\n",
        "  model = Sequential()\n",
        "  model.add(Dense(128, activation='relu', input_dim = dim, kernel_initializer='normal', kernel_regularizer=regularizers.l2(0.01)))\n",
        "  model.add(BatchNormalization(axis=-1, momentum = 0.99, epsilon = 0.001, center = True, scale = True, beta_initializer = 'zeros', gamma_initializer = 'ones', moving_mean_initializer='zeros', moving_variance_initializer='ones'))\n",
        "  model.add(Dense(128, activation='relu', kernel_initializer='normal', kernel_regularizer=regularizers.l2(0.01), activity_regularizer=regularizers.l1(0.0001)))\n",
        "  model.add(BatchNormalization(axis=-1, momentum = 0.99, epsilon = 0.001, center = True, scale = True, beta_initializer = 'zeros', gamma_initializer = 'ones', moving_mean_initializer='zeros', moving_variance_initializer='ones'))\n",
        "  model.add(Dense(128, activation='relu', kernel_initializer='normal', kernel_regularizer=regularizers.l2(0.01), activity_regularizer=regularizers.l1(0.0001)))\n",
        "  model.add(BatchNormalization(axis=-1, momentum = 0.99, epsilon = 0.001, center = True, scale = True, beta_initializer = 'zeros', gamma_initializer = 'ones', moving_mean_initializer='zeros', moving_variance_initializer='ones'))\n",
        "  model.add(Dense(128, activation='relu', kernel_initializer='normal', kernel_regularizer=regularizers.l2(0.01), activity_regularizer=regularizers.l1(0.0001)))\n",
        "  model.add(BatchNormalization(axis=-1, momentum = 0.99, epsilon = 0.001, center = True, scale = True, beta_initializer = 'zeros', gamma_initializer = 'ones', moving_mean_initializer='zeros', moving_variance_initializer='ones'))\n",
        "  model.add(Dense(128, activation='relu', kernel_initializer='normal', kernel_regularizer=regularizers.l2(0.01), activity_regularizer=regularizers.l1(0.0001)))\n",
        "  model.add(BatchNormalization(axis=-1, momentum = 0.99, epsilon = 0.001, center = True, scale = True, beta_initializer = 'zeros', gamma_initializer = 'ones', moving_mean_initializer='zeros', moving_variance_initializer='ones'))\n",
        "  model.add(Dense(128, activation='relu', kernel_initializer='normal', kernel_regularizer=regularizers.l2(0.01), activity_regularizer=regularizers.l1(0.0001)))\n",
        "  model.add(BatchNormalization(axis=-1, momentum = 0.99, epsilon = 0.001, center = True, scale = True, beta_initializer = 'zeros', gamma_initializer = 'ones', moving_mean_initializer='zeros', moving_variance_initializer='ones'))\n",
        "  model.add(Dense(128, activation='relu', kernel_initializer='normal', kernel_regularizer=regularizers.l2(0.01), activity_regularizer=regularizers.l1(0.0001)))\n",
        "  model.add(BatchNormalization(axis=-1, momentum = 0.99, epsilon = 0.001, center = True, scale = True, beta_initializer = 'zeros', gamma_initializer = 'ones', moving_mean_initializer='zeros', moving_variance_initializer='ones'))\n",
        "  model.add(Dense(128, activation='relu', kernel_initializer='normal', kernel_regularizer=regularizers.l2(0.01), activity_regularizer=regularizers.l1(0.0001)))\n",
        "  model.add(BatchNormalization(axis=-1, momentum = 0.99, epsilon = 0.001, center = True, scale = True, beta_initializer = 'zeros', gamma_initializer = 'ones', moving_mean_initializer='zeros', moving_variance_initializer='ones'))\n",
        "  model.add(Dense(128, activation='relu', kernel_initializer='normal', kernel_regularizer=regularizers.l2(0.01), activity_regularizer=regularizers.l1(0.0001)))\n",
        "  model.add(BatchNormalization(axis=-1, momentum = 0.99, epsilon = 0.001, center = True, scale = True, beta_initializer = 'zeros', gamma_initializer = 'ones', moving_mean_initializer='zeros', moving_variance_initializer='ones'))\n",
        "  model.add(Dense(128, activation='relu', kernel_initializer='normal', kernel_regularizer=regularizers.l2(0.01), activity_regularizer=regularizers.l1(0.0001)))\n",
        "  model.add(BatchNormalization(axis=-1, momentum = 0.99, epsilon = 0.001, center = True, scale = True, beta_initializer = 'zeros', gamma_initializer = 'ones', moving_mean_initializer='zeros', moving_variance_initializer='ones'))\n",
        "  model.add(Dense(128, activation='relu', kernel_initializer='normal', kernel_regularizer=regularizers.l2(0.01), activity_regularizer=regularizers.l1(0.0001)))\n",
        "  model.add(BatchNormalization(axis=-1, momentum = 0.99, epsilon = 0.001, center = True, scale = True, beta_initializer = 'zeros', gamma_initializer = 'ones', moving_mean_initializer='zeros', moving_variance_initializer='ones'))\n",
        "  model.add(Dense(128, activation='relu', kernel_initializer='normal', kernel_regularizer=regularizers.l2(0.01), activity_regularizer=regularizers.l1(0.0001)))\n",
        "  model.add(BatchNormalization(axis=-1, momentum = 0.99, epsilon = 0.001, center = True, scale = True, beta_initializer = 'zeros', gamma_initializer = 'ones', moving_mean_initializer='zeros', moving_variance_initializer='ones'))\n",
        "  model.add(Dense(64, activation='relu', kernel_initializer='normal', kernel_regularizer=regularizers.l2(0.01), activity_regularizer=regularizers.l1(0.0001)))\n",
        "  model.add(BatchNormalization(axis=-1, momentum = 0.99, epsilon = 0.001, center = True, scale = True, beta_initializer = 'zeros', gamma_initializer = 'ones', moving_mean_initializer='zeros', moving_variance_initializer='ones'))\n",
        "  model.add(Dense(32, activation='relu', kernel_initializer='normal', kernel_regularizer=regularizers.l2(0.01), activity_regularizer=regularizers.l1(0.0001)))\n",
        "  \n",
        "\t# check to see if the regression node should be added\n",
        "  if regress:\n",
        "    model.add(Dense(1, activation=\"linear\"))\n",
        " \n",
        "\t# return our model\n",
        "  return model\n",
        "  \"\"\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vn_zGcoxVr9K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# use pretrained model - Resnet50\n",
        "from keras.applications.resnet50 import ResNet50\n",
        "from keras.preprocessing import image\n",
        "from keras.models import Model\n",
        "from keras.layers import Dense, GlobalAveragePooling2D\n",
        "from keras import backend as K\n",
        "\n",
        "def cnn_model(regress=False):\n",
        "\n",
        "  base_model = ResNet50(weights='imagenet', include_top=False)\n",
        "\n",
        "  # add a global spatial average pooling layer\n",
        "  x = base_model.output\n",
        "  x = GlobalAveragePooling2D()(x)\n",
        "  # let's add a fully-connected layer\n",
        "  x = Dropout(0.5)(x)\n",
        "  x = Dense(1024, activation='relu')(x)\n",
        "  x = Dropout(0.5)(x)\n",
        "  x = Dense(1024, activation = 'relu')(x)\n",
        "\n",
        "  # check to see if the regression node should be added\n",
        "  if regress:\n",
        "      x = Dense(1, activation=\"linear\")(x)\n",
        "\n",
        "  for layer in base_model.layers:\n",
        "      layer.trainable = False\n",
        "\n",
        "  # construct the CNN\n",
        "  model = Model(inputs=base_model.input, outputs=x)\n",
        "\n",
        "  # return the CNN\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jVltsi5VfDXi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create the numerical and CNN models\n",
        "numeric = numerical_model(104, regress=False)\n",
        "cnn = cnn_model(regress=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vOzbYZfuiNRR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.layers import concatenate\n",
        "\n",
        "# create the input to our final set of layers as the *output* of both the numeric and CNN\n",
        "combinedInput = concatenate([numeric.output, cnn.output])\n",
        "\n",
        "print(combinedInput.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pt_fGTufYiKB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# our final FC layer head will have two dense layers, the final one\n",
        "# being our regression head\n",
        "x = Dense(1024, activation='relu', kernel_initializer='normal', kernel_regularizer=regularizers.l2(0.01), activity_regularizer=regularizers.l1(0.0001))(combinedInput)\n",
        "x = BatchNormalization(axis=-1, momentum = 0.99, epsilon = 0.001, center = True, scale = True, beta_initializer = 'zeros', gamma_initializer = 'ones', moving_mean_initializer='zeros', moving_variance_initializer='ones')(x)\n",
        "x = Dense(512, activation='relu', kernel_initializer='normal', kernel_regularizer=regularizers.l2(0.01), activity_regularizer=regularizers.l1(0.0001))(x)\n",
        "x = BatchNormalization(axis=-1, momentum = 0.99, epsilon = 0.001, center = True, scale = True, beta_initializer = 'zeros', gamma_initializer = 'ones', moving_mean_initializer='zeros', moving_variance_initializer='ones')(x)\n",
        "x = Dense(1, activation='linear', kernel_initializer='normal')(x)\n",
        "\n",
        "# our final model will accept categorical/numerical data on the MLP\n",
        "# input and images on the CNN input, outputting a single value (the\n",
        "# predicted price of the house)\n",
        "model = Model(inputs=[numeric.input, cnn.input], outputs=x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oRI478hHjcde",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# root mean squared error (rmse) for regression\n",
        "def rmse(y_true, y_pred):\n",
        "    from keras import backend\n",
        "    return backend.sqrt(backend.mean(backend.square(y_pred - y_true), axis=-1))\n",
        "\n",
        "# mean squared error (mse) for regression\n",
        "def mse(y_true, y_pred):\n",
        "    from keras import backend\n",
        "    return backend.mean(backend.square(y_pred - y_true), axis=-1)\n",
        "\n",
        "# coefficient of determination (R^2) for regression\n",
        "def r_square(y_true, y_pred):\n",
        "    from keras import backend as K\n",
        "    SS_res =  K.sum(K.square(y_true - y_pred)) \n",
        "    SS_tot = K.sum(K.square(y_true - K.mean(y_true))) \n",
        "    return (1 - SS_res/(SS_tot + K.epsilon()))\n",
        "\n",
        "def r_square_loss(y_true, y_pred):\n",
        "    from keras import backend as K\n",
        "    SS_res =  K.sum(K.square(y_true - y_pred)) \n",
        "    SS_tot = K.sum(K.square(y_true - K.mean(y_true))) \n",
        "    return 1 - ( 1 - SS_res/(SS_tot + K.epsilon()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Ji3ZByEai2e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.optimizers import Adam\n",
        "\n",
        "# compile the model using mean absolute percentage error as our loss,\n",
        "# implying that we seek to minimize the absolute percentage difference\n",
        "# between our price *predictions* and the *actual prices*\n",
        "opt = Adam(lr=1e-3, decay=1e-3 / 200)\n",
        "model.compile(loss=\"mean_absolute_percentage_error\", optimizer=opt, metrics=[\"mean_absolute_percentage_error\", r_square])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k-LBnJbIb65R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# train the model\n",
        "print(\"[INFO] training model...\")\n",
        "result = model.fit(\n",
        "\t[X_numeric_train_scaled, X_image_trainarray], Y_train_loghammerprice,\n",
        "\tvalidation_data=([X_numeric_dev_scaled, X_image_devarray], Y_dev_loghammerprice),\n",
        "\tepochs=5, batch_size=512)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NhUb2dROmeM4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred = model.predict([X_numeric_test_scaled, X_image_testarray])\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i4b8DqPAysnR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# compute the difference between the *predicted* house prices and the\n",
        "# *actual* house prices, then compute the percentage difference and\n",
        "# the absolute percentage difference\n",
        "diff = y_pred.flatten() - Y_test_loghammerprice\n",
        "percentDiff = (diff / Y_test_loghammerprice) * 100\n",
        "absPercentDiff = np.abs(percentDiff)\n",
        " \n",
        "# compute the mean and standard deviation of the absolute percentage\n",
        "# difference\n",
        "mean = np.mean(absPercentDiff)\n",
        "std = np.std(absPercentDiff)\n",
        " \n",
        "# finally, show some statistics on our model\n",
        "print(\"[INFO] mean: {:.2f}%, std: {:.2f}%\".format(mean, std))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b8cYLWp2mrlc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# plot training curve for R^2 (beware of scale, starts very low negative)\n",
        "plt.plot(result.history['val_r_square'])\n",
        "plt.plot(result.history['r_square'])\n",
        "plt.title('model R^2')\n",
        "plt.ylabel('R^2')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()\n",
        "           \n",
        "# plot training curve for rmse\n",
        "plt.plot(result.history['rmse'])\n",
        "plt.plot(result.history['val_rmse'])\n",
        "plt.title('rmse')\n",
        "plt.ylabel('rmse')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "# print the linear regression and display datapoints\n",
        "from sklearn.linear_model import LinearRegression  \n",
        "regressor = LinearRegression()  \n",
        "regressor.fit(Y_test_loghammerprice.reshape(-1,1), y_pred)  \n",
        "y_fit = regressor.predict(y_pred) \n",
        "\n",
        "reg_intercept = round(regressor.intercept_[0],4)\n",
        "reg_coef = round(regressor.coef_.flatten()[0],4)\n",
        "reg_label = \"y = \" + str(reg_intercept) + \"*x +\" + str(reg_coef)\n",
        "\n",
        "plt.scatter(Y_test_loghammerprice, y_pred, color='blue', label= 'data')\n",
        "plt.plot(y_pred, y_fit, color='red', linewidth=2, label = 'Linear regression\\n'+reg_label) \n",
        "plt.title('Linear Regression')\n",
        "plt.legend()\n",
        "plt.xlabel('observed')\n",
        "plt.ylabel('predicted')\n",
        "plt.show()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FuKojMKpb-F7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# evaluate the model\n",
        "model.evaluate(x = [X_numeric_test_scaled, X_image_testarray], y = Y_test_loghammerprice)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S9QfVGgLbZ-x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# split training set and test set (actually, it is \"Validation set\")\n",
        "#x_Image_array_resized_train, x_Image_array_resized_test, load_bin_train, load_bin_test = train_test_split(x_Image_array, dummy_load_bin, test_size=0.25)\n",
        "\n",
        "#x_train = np.multiply(x_Image_array_resized_train, 1/255)\n",
        "#x_test = np.multiply(x_Image_array_resized_test, 1/255)\n",
        "#y_train = load_bin_train\n",
        "#y_test = load_bin_test\n",
        "\n",
        "#print(x_train.shape, x_test.shape, y_train.shape, y_test.shape)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UuyKLtUKedqa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "load_ext tensorboard"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "spHH2zajM6yb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!rm -rf ./logs/ "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x_C1AuQPdwN4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from time import time\n",
        "from datetime import datetime\n",
        "from packaging import version\n",
        "from keras.callbacks import TensorBoard\n",
        "from tensorboard.plugins.hparams import api as hp\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JOhuSPFEM3PI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "HP_NUM_UNITS = hp.HParam('num_units', hp.Discrete([16, 32]))\n",
        "HP_DROPOUT = hp.HParam('dropout', hp.Discrete([0.1, 0.2]))\n",
        "#HP_OPTIMIZER = hp.HParam('optimizer', hp.Discrete(['adam', 'sgd']))\n",
        "HP_KERNEL = hp.HParam('kernel_size', hp.Discrete([5, 7]))\n",
        "\n",
        "METRIC_ACCURACY = 'accuracy'\n",
        "\n",
        "with tf.summary.FileWriter('logs/hparam_tuning'):\n",
        "  hp.hparams_config(\n",
        "    hparams=[HP_NUM_UNITS, HP_DROPOUT, HP_KERNEL],\n",
        "    metrics=[hp.Metric(METRIC_ACCURACY, display_name='Accuracy')],\n",
        "  )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OZtVUSp7v8ed",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def train_test_model(hparams):\n",
        "  input_shape = (224,224,3)\n",
        "  # hparams[HP_KERNEL] = 7\n",
        "  # hparams[HP_NUM_UNITS] = 32\n",
        "  pool_size = 3\n",
        "  final_node_size = dummy_load_bin.shape[1]\n",
        "\n",
        "  model = Sequential()\n",
        "\n",
        "  model.add(Conv2D(hparams[HP_NUM_UNITS], (hparams[HP_KERNEL], hparams[HP_KERNEL]), activation='relu', padding='same', input_shape=input_shape))\n",
        "  model.add(BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001, center=True, scale=True, beta_initializer='zeros', gamma_initializer='ones', moving_mean_initializer='zeros', moving_variance_initializer='ones'))\n",
        "  model.add(MaxPooling2D((pool_size, pool_size), strides=(2, 2), padding='same'))\n",
        "  \n",
        "  model.add(Conv2D(hparams[HP_NUM_UNITS], (hparams[HP_KERNEL], hparams[HP_KERNEL]), activation='relu', padding='same'))\n",
        "  model.add(BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001, center=True, scale=True, beta_initializer='zeros', gamma_initializer='ones', moving_mean_initializer='zeros', moving_variance_initializer='ones'))\n",
        "  model.add(MaxPooling2D((pool_size, pool_size), strides=(2, 2), padding='same'))\n",
        "\n",
        "  model.add(Conv2D(hparams[HP_NUM_UNITS], (hparams[HP_KERNEL], hparams[HP_KERNEL]), activation='relu', padding='same'))\n",
        "  model.add(BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001, center=True, scale=True, beta_initializer='zeros', gamma_initializer='ones', moving_mean_initializer='zeros', moving_variance_initializer='ones'))\n",
        "  #model.add(MaxPooling2D((pool_size, pool_size), strides=(2, 2), padding='same'))\n",
        "  model.add(Dropout(hparams[HP_DROPOUT]))\n",
        "    \n",
        "  model.add(Conv2D(hparams[HP_NUM_UNITS], (hparams[HP_KERNEL], hparams[HP_KERNEL]), activation='relu', padding='same'))\n",
        "  model.add(BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001, center=True, scale=True, beta_initializer='zeros', gamma_initializer='ones', moving_mean_initializer='zeros', moving_variance_initializer='ones'))\n",
        "  #model.add(MaxPooling2D((pool_size, pool_size), strides=(2, 2), padding='same'))\n",
        "  model.add(Dropout(hparams[HP_DROPOUT]))\n",
        "\n",
        "  model.add(Conv2D(hparams[HP_NUM_UNITS], (hparams[HP_KERNEL], hparams[HP_KERNEL]), activation='relu', padding='same'))\n",
        "  model.add(BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001, center=True, scale=True, beta_initializer='zeros', gamma_initializer='ones', moving_mean_initializer='zeros', moving_variance_initializer='ones'))\n",
        "  model.add(MaxPooling2D((pool_size, pool_size), strides=(2, 2), padding='same'))\n",
        "    \n",
        "  model.add(Conv2D(hparams[HP_NUM_UNITS], (hparams[HP_KERNEL], hparams[HP_KERNEL]), activation='relu', padding='same'))\n",
        "  model.add(BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001, center=True, scale=True, beta_initializer='zeros', gamma_initializer='ones', moving_mean_initializer='zeros', moving_variance_initializer='ones'))\n",
        "  model.add(MaxPooling2D((pool_size, pool_size), strides=(2, 2), padding='same'))\n",
        "  #model.add(Dropout(hparams[HP_DROPOUT]))\n",
        "\n",
        "  #model.add(Conv2D(hparams[HP_NUM_UNITS], (hparams[HP_KERNEL], hparams[HP_KERNEL]), activation='relu', padding='same'))\n",
        "  #model.add(BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001, center=True, scale=True, beta_initializer='zeros', gamma_initializer='ones', moving_mean_initializer='zeros', moving_variance_initializer='ones'))\n",
        "  #model.add(MaxPooling2D((pool_size, pool_size), strides=(2, 2), padding='same'))\n",
        "\n",
        "  #model.add(Conv2D(hparams[HP_NUM_UNITS], (hparams[HP_KERNEL], hparams[HP_KERNEL]), activation='relu', padding='same'))\n",
        "  #model.add(BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001, center=True, scale=True, beta_initializer='zeros', gamma_initializer='ones', moving_mean_initializer='zeros', moving_variance_initializer='ones'))\n",
        "  #model.add(MaxPooling2D((pool_size, pool_size), strides=(2, 2), padding='same'))\n",
        "  #model.add(Dropout(hparams[HP_DROPOUT]))\n",
        "\n",
        "  model.add(Conv2D(hparams[HP_NUM_UNITS], (hparams[HP_KERNEL], hparams[HP_KERNEL]), activation='relu', padding='same'))\n",
        "  model.add(BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001, center=True, scale=True, beta_initializer='zeros', gamma_initializer='ones', moving_mean_initializer='zeros', moving_variance_initializer='ones'))\n",
        "  model.add(MaxPooling2D((pool_size, pool_size), strides=(2, 2), padding='same'))\n",
        "  model.add(Dropout(hparams[HP_DROPOUT]))\n",
        "\n",
        "  model.add(Conv2D(hparams[HP_NUM_UNITS], (hparams[HP_KERNEL], hparams[HP_KERNEL]), activation='relu', padding='same'))\n",
        "  model.add(BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001, center=True, scale=True, beta_initializer='zeros', gamma_initializer='ones', moving_mean_initializer='zeros', moving_variance_initializer='ones'))\n",
        "  model.add(MaxPooling2D((pool_size, pool_size), strides=(2, 2), padding='same'))\n",
        "  model.add(Dropout(hparams[HP_DROPOUT]))\n",
        "\n",
        "  model.add(Flatten())\n",
        "  model.add(Dense(final_node_size, activation='softmax'))\n",
        "    \n",
        "  model.compile(loss=keras.losses.categorical_crossentropy, optimizer=keras.optimizers.Adam(),metrics=['accuracy'])\n",
        "\n",
        "  model.fit(x_train, y_train, batch_size=32, epochs=10) #, callbacks=[hp.KerasCallback('logs/hparam_tuning/', hparams)])\n",
        "  _, accuracy = model.evaluate(x_test, y_test) \n",
        "\n",
        "  return accuracy\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5BUksRHfRJAv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def run(run_dir, hparams):\n",
        "  with tf.summary.FileWriter(run_dir):\n",
        "    hp.hparams(hparams)  # record the values used in this trial\n",
        "    accuracy = train_test_model(hparams)\n",
        "    tf.summary.scalar(METRIC_ACCURACY, accuracy)#, step=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8RdV3z0ahQFS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "log_dir=\"logs/fit/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "\n",
        "### When training Keras models, you can use callbacks instead of writing these directly:\n",
        "#tensorboard_callback = keras.callbacks.TensorBoard(log_dir=log_dir.format(time()))\n",
        "#hp_callback = hp.KerasCallback(log_dir, hparams)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Fxuo2EDR1Ze",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "session_num = 0\n",
        "\n",
        "for num_units in HP_NUM_UNITS.domain.values:\n",
        "  for dropout_rate in HP_DROPOUT.domain.values:\n",
        "    for kernel_size in HP_KERNEL.domain.values:\n",
        "      hparams = {\n",
        "          HP_NUM_UNITS: num_units,\n",
        "          HP_DROPOUT: dropout_rate,\n",
        "          HP_KERNEL: kernel_size,\n",
        "      }\n",
        "      run_name = \"run-%d\" % session_num\n",
        "      print('--- Starting trial: %s' % run_name)\n",
        "      print({h.name: hparams[h] for h in hparams})\n",
        "      run('logs/hparam_tuning/' + run_name, hparams)\n",
        "      session_num += 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EwBjXY0QRrME",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#history = model.fit(x_train, y_train, batch_size=32, epochs=1, verbose=1, validation_data=(x_test, y_test), callbacks=[tensorboard_callback, hp_callback])\n",
        "#history = model.fit(x_train, y_train, batch_size=32, epochs=50, callbacks=[tensorboard_callback])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pH6UtJWQ1XYY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# This evaluation is not actually done right. Need to get the real evaluation dataset (2018 and beyond)\n",
        "#score = model.evaluate(x_test, y_test, verbose=1)\n",
        "#print('Test loss:', score[0])\n",
        "#print('Test accuracy:', score[1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j0xOGgEniBT5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#%tensorboard --logdir logs/fit\n",
        "%tensorboard --logdir logs/hparam_tuning/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lpq8SlEEU3x4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# list all data in history\n",
        "print(history.history.keys())\n",
        "# summarize history for accuracy\n",
        "plt.plot(history.history['acc'])\n",
        "plt.plot(history.history['val_acc'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()\n",
        "# summarize history for loss\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ud7X-O1azZr8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#################################\n",
        "## TEXT NET #####################\n",
        "#################################"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hLToTfdH0UfS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "load_text"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k1Jqjqr0KoOr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# split training set and validation set\n",
        "#load_text = load_text.values\n",
        "X_text_train, X_text_test, Y_text_train, Y_text_test = train_test_split(load_text, dummy_load_bin, test_size=0.1)\n",
        "print(X_text_train.shape, Y_text_train.shape,X_text_test.shape, Y_text_test.shape)\n",
        "X_text_test[:,10]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pp8C0vMQlbPT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Split columns to StandardScalar the table more effectively. \n",
        "\n",
        "X_text_train_1 = X_text_train[:,:11]\n",
        "X_text_train_2 = X_text_train[:,11:]\n",
        "\n",
        "print(\"X_text_train_1\", X_text_train_1.shape)\n",
        "print(\"X_text_train_2\", X_text_train_2.shape)\n",
        "\n",
        "X_text_test_1 = X_text_test[:, :11]\n",
        "X_text_test_2 = X_text_test[:,11:]\n",
        "\n",
        "print(\"X_text_test_1\", X_text_test_1.shape)\n",
        "print(\"X_text_test_2\", X_text_test_2.shape)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SsH8c0v6cqwu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " #standardize X_train and X_test using mean and standard deviation of training samples\n",
        "scaler = StandardScaler()\n",
        "\n",
        "scaler.fit(X_text_train_1)\n",
        "X_text_train_1_scaled = scaler.transform(X_text_train_1)\n",
        "X_text_test_1_scaled = scaler.transform(X_text_test_1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "atanz44V2UiF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# construct our training and testing data points by concatenating the categorical features with the continuous features\n",
        "X_text_train_scaled = np.hstack([X_text_train_1_scaled, X_text_train_2])\n",
        "X_text_test_scaled = np.hstack([X_text_test_1_scaled, X_text_test_2])\n",
        "#X_dev_scaled = np.hstack([X_dev_scaled, X_dev_2])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ix9EfM-b2kw4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "final_node_size = dummy_load_bin.shape[1]\n",
        "\n",
        "#Create model\n",
        "model = Sequential()\n",
        "\n",
        "from keras.layers import BatchNormalization\n",
        "from keras import regularizers\n",
        "\n",
        "#Add more layers\n",
        "model.add(Dense(128, activation='relu', input_shape = (104,), kernel_initializer='normal', kernel_regularizer=regularizers.l2(0.01)))\n",
        "#model.add(Dropout(0.5))\n",
        "model.add(BatchNormalization(axis=-1, momentum = 0.99, epsilon = 0.001, center = True, scale = True, beta_initializer = 'zeros', gamma_initializer = 'ones', moving_mean_initializer='zeros', moving_variance_initializer='ones'))\n",
        "model.add(Dense(128, activation='relu', kernel_initializer='normal', kernel_regularizer=regularizers.l2(0.01), activity_regularizer=regularizers.l1(0.0001)))\n",
        "model.add(BatchNormalization(axis=-1, momentum = 0.99, epsilon = 0.001, center = True, scale = True, beta_initializer = 'zeros', gamma_initializer = 'ones', moving_mean_initializer='zeros', moving_variance_initializer='ones'))\n",
        "model.add(Dense(128, activation='relu', kernel_initializer='normal', kernel_regularizer=regularizers.l2(0.01), activity_regularizer=regularizers.l1(0.0001)))\n",
        "model.add(BatchNormalization(axis=-1, momentum = 0.99, epsilon = 0.001, center = True, scale = True, beta_initializer = 'zeros', gamma_initializer = 'ones', moving_mean_initializer='zeros', moving_variance_initializer='ones'))\n",
        "model.add(Dense(128, activation='relu', kernel_initializer='normal', kernel_regularizer=regularizers.l2(0.01), activity_regularizer=regularizers.l1(0.0001)))\n",
        "model.add(BatchNormalization(axis=-1, momentum = 0.99, epsilon = 0.001, center = True, scale = True, beta_initializer = 'zeros', gamma_initializer = 'ones', moving_mean_initializer='zeros', moving_variance_initializer='ones'))\n",
        "model.add(Dense(128, activation='relu', kernel_initializer='normal', kernel_regularizer=regularizers.l2(0.01), activity_regularizer=regularizers.l1(0.0001)))\n",
        "model.add(BatchNormalization(axis=-1, momentum = 0.99, epsilon = 0.001, center = True, scale = True, beta_initializer = 'zeros', gamma_initializer = 'ones', moving_mean_initializer='zeros', moving_variance_initializer='ones'))\n",
        "model.add(Dense(128, activation='relu', kernel_initializer='normal', kernel_regularizer=regularizers.l2(0.01), activity_regularizer=regularizers.l1(0.0001)))\n",
        "model.add(BatchNormalization(axis=-1, momentum = 0.99, epsilon = 0.001, center = True, scale = True, beta_initializer = 'zeros', gamma_initializer = 'ones', moving_mean_initializer='zeros', moving_variance_initializer='ones'))\n",
        "model.add(Dense(128, activation='relu', kernel_initializer='normal', kernel_regularizer=regularizers.l2(0.01), activity_regularizer=regularizers.l1(0.0001)))\n",
        "model.add(BatchNormalization(axis=-1, momentum = 0.99, epsilon = 0.001, center = True, scale = True, beta_initializer = 'zeros', gamma_initializer = 'ones', moving_mean_initializer='zeros', moving_variance_initializer='ones'))\n",
        "model.add(Dense(128, activation='relu', kernel_initializer='normal', kernel_regularizer=regularizers.l2(0.01), activity_regularizer=regularizers.l1(0.0001)))\n",
        "model.add(BatchNormalization(axis=-1, momentum = 0.99, epsilon = 0.001, center = True, scale = True, beta_initializer = 'zeros', gamma_initializer = 'ones', moving_mean_initializer='zeros', moving_variance_initializer='ones'))\n",
        "model.add(Dense(128, activation='relu', kernel_initializer='normal', kernel_regularizer=regularizers.l2(0.01), activity_regularizer=regularizers.l1(0.0001)))\n",
        "model.add(BatchNormalization(axis=-1, momentum = 0.99, epsilon = 0.001, center = True, scale = True, beta_initializer = 'zeros', gamma_initializer = 'ones', moving_mean_initializer='zeros', moving_variance_initializer='ones'))\n",
        "model.add(Dense(128, activation='relu', kernel_initializer='normal', kernel_regularizer=regularizers.l2(0.01), activity_regularizer=regularizers.l1(0.0001)))\n",
        "model.add(BatchNormalization(axis=-1, momentum = 0.99, epsilon = 0.001, center = True, scale = True, beta_initializer = 'zeros', gamma_initializer = 'ones', moving_mean_initializer='zeros', moving_variance_initializer='ones'))\n",
        "model.add(Dense(128, activation='relu', kernel_initializer='normal', kernel_regularizer=regularizers.l2(0.01), activity_regularizer=regularizers.l1(0.0001)))\n",
        "model.add(BatchNormalization(axis=-1, momentum = 0.99, epsilon = 0.001, center = True, scale = True, beta_initializer = 'zeros', gamma_initializer = 'ones', moving_mean_initializer='zeros', moving_variance_initializer='ones'))\n",
        "model.add(Dense(128, activation='relu', kernel_initializer='normal', kernel_regularizer=regularizers.l2(0.01), activity_regularizer=regularizers.l1(0.0001)))\n",
        "model.add(BatchNormalization(axis=-1, momentum = 0.99, epsilon = 0.001, center = True, scale = True, beta_initializer = 'zeros', gamma_initializer = 'ones', moving_mean_initializer='zeros', moving_variance_initializer='ones'))\n",
        "model.add(Dense(64, activation='relu', kernel_initializer='normal', kernel_regularizer=regularizers.l2(0.01), activity_regularizer=regularizers.l1(0.0001)))\n",
        "model.add(BatchNormalization(axis=-1, momentum = 0.99, epsilon = 0.001, center = True, scale = True, beta_initializer = 'zeros', gamma_initializer = 'ones', moving_mean_initializer='zeros', moving_variance_initializer='ones'))\n",
        "model.add(Dense(32, activation='relu', kernel_initializer='normal', kernel_regularizer=regularizers.l2(0.01), activity_regularizer=regularizers.l1(0.0001)))\n",
        "#model.add(Dropout(0.5))\n",
        "model.add(Dense(final_node_size, activation='softmax', kernel_initializer='normal', kernel_regularizer=regularizers.l2(0.01), activity_regularizer=regularizers.l1(0.0001)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yc7LBgvMYWK7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# complie the model using adam optimizer and categorical crossentropy \n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy',metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LEvZF0Is26k8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.summary()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N4gmvXa23rJt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import datetime\n",
        "\n",
        "log_dir=\"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cOeH7iVj3yf2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# train the model\n",
        "#hist = model.fit(X_text_train_scaled, Y_text_train, batch_size=64, epochs=100, shuffle=True, callbacks=[tensorboard_callback])\n",
        "hist = model.fit(X_text_train_scaled, Y_text_train, batch_size=64, epochs=100,validation_data= (X_text_test_scaled, Y_text_test), shuffle=True, callbacks=[tensorboard_callback])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dNR_ChetYg_Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.evaluate(x = X_text_test_scaled, y = Y_text_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AOjjuB4cY-8Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# plot the loss\n",
        "plt.plot(hist.history['loss'])\n",
        "plt.plot(hist.history['val_loss'])\n",
        "plt.title('Model loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Val'], loc = 'upper right')\n",
        "plt.show()\n",
        "\n",
        "\n",
        "#plot the accuracy\n",
        "plt.plot(hist.history['acc'])\n",
        "plt.plot(hist.history['val_acc'])\n",
        "plt.title('Model accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Val'], loc = 'lower right')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t2kX3ymqZFMe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!tensorboard --logdir logs/fit"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7co4iDhl4Tth",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}